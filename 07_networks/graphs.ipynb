{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Mimicking The Peregrine</h1>\n",
    "Didi Chang-Park\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "text_folder = '../corpora/peregrine/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thanks to ryan for this method, which I've slightly modified\n",
    "def draw_graph3(networkx_graph,notebook=True,output_filename='graph.html',show_buttons=False,only_physics_buttons=False):\n",
    "    # import\n",
    "    from pyvis import network as net\n",
    "    \n",
    "    # make a pyvis network\n",
    "    pyvis_graph = net.Network(notebook=notebook, height=\"750px\", width=\"100%\")\n",
    "    \n",
    "    # for each node and its attributes in the networkx graph\n",
    "    for node,node_attrs in networkx_graph.nodes(data=True):\n",
    "        pyvis_graph.add_node(node,**node_attrs)\n",
    "        \n",
    "    # for each edge and its attributes in the networkx graph\n",
    "    for source,target,edge_attrs in networkx_graph.edges(data=True):\n",
    "        # if value/width not specified directly, and weight is specified, set 'value' to 'weight'\n",
    "        if not 'value' in edge_attrs and not 'width' in edge_attrs and 'weight' in edge_attrs:\n",
    "            # place at key 'value' the weight of the edge\n",
    "            edge_attrs['value']=edge_attrs['weight']\n",
    "        # add the edge\n",
    "        pyvis_graph.add_edge(source,target,**edge_attrs)\n",
    "\n",
    "    pyvis_graph.set_edge_smooth('dynamic')\n",
    "    # return and also save\n",
    "    return pyvis_graph.show(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import pyvis\n",
    "from pyvis.network import Network\n",
    "lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.append('is')\n",
    "stop_words.remove('as')\n",
    "stop_words.append('a')\n",
    "parts = ['N','V','A','D','P']\n",
    "colordict = {}\n",
    "colordict['N'] = ['green',15]\n",
    "colordict['V'] = ['red',15]\n",
    "colordict['A'] = ['pink',15]\n",
    "colordict['D'] = ['#c0c1c4',15]\n",
    "colordict['P'] = ['yellow',15]\n",
    "birds = ('falcon',\"peregrine\",\"tiercel\",\"lapwing\",\"woodcock\",\"curlew\",\"heron\",\"sandpiper\",\n",
    "        \"snipe\",\"wigeon\",\"starling\",\"skylark\",\"gull\",\"owl\",\"mallard\",\"woodpigeons\",\"swan\",\n",
    "        \"jackdaw\",\"lark\",\"plover\",\"partridge\",\"pigeon\",\"duck\",\"hawk\",\"crow\",\"teal\",\"wildfowl\",\n",
    "        \"blackbird\",\"bunting\",\"swallow\",\"martin\",\"kestrel\",\"jay\",\"plover\",\"sanderling\",\n",
    "        \"wader\",\"pheasant\",\"greenshank\",\"grebe\",\"pied\",\"wagtail\",\"moorhen\",\"thrush\",\"finch\")\n",
    "for bird in birds:\n",
    "    colordict[bird] = [\"blue\",40]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes word frequency dictionary for entire corpus\n",
    "with open(text_folder+\"/hidden/the-hunting-life.txt\") as file:\n",
    "    filetext = file.read().lower().split()\n",
    "with open(text_folder+\"hidden/markov-life.txt\",\"w\") as file:\n",
    "    for fn in os.listdir(text_folder):\n",
    "        if(fn[0]==\"_\"):\n",
    "            file.write(open(text_folder+fn).read()+\"\\n\")\n",
    "markovtext = open(text_folder+\"hidden/markov-life.txt\",\"r\").read().lower().split()\n",
    "new = filetext+markovtext\n",
    "words = []\n",
    "for word in new:\n",
    "    if(word==\"as\"):\n",
    "        words.append(word)\n",
    "    if(word==\"was\"):\n",
    "        words.append(word)\n",
    "    else:\n",
    "        words.append(lemma.lemmatize(re.sub(r'[^\\w\\-\\s]', '', word)))\n",
    "freqdist={}\n",
    "for word in words:\n",
    "    if word not in freqdist.keys():\n",
    "        freqdist[word]=1\n",
    "    else:\n",
    "        freqdist[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getsents(text):\n",
    "    #with open(text_folder+fn) as file:\n",
    "    #    filetext = file.read().lower()\n",
    "    sents_unstripped = nltk.sent_tokenize(text.lower())\n",
    "    sents_unstopped = []\n",
    "    for s in sents_unstripped:\n",
    "        sents_unstopped.append(re.sub(r'[^\\w\\-\\s]', '',s).split())\n",
    "    sents = []\n",
    "    for s in sents_unstopped:\n",
    "        st = []\n",
    "        for w in s:\n",
    "            if w not in stop_words:\n",
    "                if(w==\"as\"):\n",
    "                    st.append(\"as\")\n",
    "                if(w==\"was\"):\n",
    "                    st.append(\"was\")\n",
    "                else:\n",
    "                    st.append(lemma.lemmatize(w))\n",
    "        sents.append(st)\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParts(sents):\n",
    "    sent_holder = []    \n",
    "    part_dict = {}\n",
    "    for s in sents:\n",
    "        tags = nltk.pos_tag(s)\n",
    "        sholder = []\n",
    "        for tag in tags:\n",
    "            if(tag[1][:1] in parts):\n",
    "                sholder.append(tag[0])\n",
    "            part_dict[tag[0]] = tag[1]\n",
    "        if(len(sholder)!=0):\n",
    "            sent_holder.append(sholder)\n",
    "    return part_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makegraph(sents):\n",
    "    G = nx.Graph()\n",
    "    part_dict = getParts(sents)\n",
    "    \n",
    "    num_sents = len(sents)\n",
    "    storelast = \"\"\n",
    "    for s in sents:\n",
    "        bigs = list(nltk.bigrams(s))\n",
    "        if(len(bigs)>0):\n",
    "            if sents.index(s)>0:\n",
    "                G.add_edge(storelast, bigs[0][0])\n",
    "            for pair in bigs:\n",
    "                p0 = part_dict[pair[0]][:1]\n",
    "                p1 = part_dict[pair[1]][:1]\n",
    "                size0 = 1/freqdist[pair[0]]*30+10\n",
    "                size1 = 1/freqdist[pair[1]]*30+10\n",
    "                attribs=['#8c8c8c','#8c8c8c',7,7]\n",
    "                if(p0 in colordict):\n",
    "                    attribs[0]=colordict[p0][0]\n",
    "                if(p1 in colordict):\n",
    "                    attribs[1]=colordict[p1][0]\n",
    "                if(pair[0] in birds):\n",
    "                    attribs[0] = \"blue\"\n",
    "                    size0+=30\n",
    "                if(pair[1] in birds):\n",
    "                    attribs[1] = \"blue\"\n",
    "                    size1+=30\n",
    "                G.add_node(pair[0],color=attribs[0], size=size0)\n",
    "                G.add_node(pair[1],color=attribs[1], size=size1)\n",
    "                if(\"peregrine\" in s):\n",
    "                    edgec = \"blue\"\n",
    "                else:\n",
    "                    edgec = \"red\"\n",
    "                G.add_edge(pair[0], pair[1],color=edgec)\n",
    "            if sents.index(s)<num_sents-1:\n",
    "                storelast = bigs[len(bigs)-1][1]\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify\n",
    "import numpy\n",
    "import natsort\n",
    "import matplotlib.pyplot as plt\n",
    "text_folder = '../corpora/peregrine/'\n",
    "\n",
    "seasons = {\n",
    "    \"oct\" : \"fall\",\n",
    "    \"nov\" : \"fall\",\n",
    "    \"dec\" : \"winter\",\n",
    "    \"jan\" : \"winter\",\n",
    "    \"feb\" : \"winter\",\n",
    "    \"mar\" : \"spring\",\n",
    "    \"apr\" : \"spring\"\n",
    "}\n",
    "ss = 3 #state size   \n",
    "\n",
    "with open(text_folder+\"/hidden/the-hunting-life.txt\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "seasons_texts = {}\n",
    "for season in seasons.values():\n",
    "    with open(text_folder+\"/hidden/seasons/\"+season+\".txt\") as f:\n",
    "        text = f.read()\n",
    "        seasons_texts[season] = text\n",
    "    \n",
    "with open(text_folder+\"/hidden/first-lines.txt\") as f:\n",
    "    text = f.read()\n",
    "    firstline_model = markovify.Text(text, state_size=ss)\n",
    "    \n",
    "def markovify(fn):\n",
    "    import markovify\n",
    "    whole_model = markovify.Text(text, state_size=ss)\n",
    "    with open(text_folder+fn) as f:\n",
    "        txt = f.read()\n",
    "        txt_model = markovify.Text(txt, state_size=ss)\n",
    "    season_model = markovify.Text(seasons_texts[seasons[fn[3:6]]], state_size=ss)\n",
    "    full_model = markovify.combine([whole_model, season_model,txt_model], [1,2,2.5])\n",
    "    first_model = markovify.combine([firstline_model,season_model],[2,1])\n",
    "    new_text=\"\"\n",
    "    sd = sent_data(fn)\n",
    "    num_sents = sd[1][4]\n",
    "    max_len = sd[1][0]\n",
    "    wc = sd[1][5]\n",
    "    curlen = 0\n",
    "    while True:\n",
    "        new = first_model.make_sentence()\n",
    "        if(new!=None):\n",
    "            new_text+=(new+\" \")\n",
    "            curlen+=(new.count(\" \")+1)\n",
    "            break\n",
    "    else:\n",
    "        new = first_model.make_sentence()\n",
    "    i=1\n",
    "    while i<num_sents:\n",
    "        new = full_model.make_sentence()\n",
    "        if(new!=None):\n",
    "            new_text+=(new+\" \")\n",
    "            curlen+=new.count(\" \")+1\n",
    "            i+=1\n",
    "    m = open(text_folder+\"_\"+fn, \"w+\")\n",
    "    m.write(new_text)\n",
    "    m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_data(filename):\n",
    "    import numpy\n",
    "    sent_len = []\n",
    "    with open(text_folder+filename) as f:\n",
    "        text = f.read().strip(\"\\n\").split(\".\")\n",
    "        text[0]+=\" \"\n",
    "        rare=0\n",
    "        for sent in text:\n",
    "            if(sent!=\" \" and sent!=\"\"):\n",
    "                sentlen = sent.count(\" \")\n",
    "                sent_len.append(sentlen)\n",
    "            for w in sent:\n",
    "                if(w in freqdist.keys()):\n",
    "                    if(freqdist[w]<2):\n",
    "                        rare+=1\n",
    "        \n",
    "        #max sent length, min sent length, mean sent length, standard deviation on sent length,  number of words, number of rare words, num sentences\n",
    "        data = [max(sent_len), min(sent_len),sum(sent_len)/len(sent_len), numpy.std(sent_len), sum(sent_len),rare, len(sent_len)]\n",
    "    return([sent_len,data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates the CSV metadata\n",
    "dr=os.listdir(text_folder)\n",
    "nr = natsort.natsorted(dr)\n",
    "with open(text_folder+\"peregrine.csv\", \"w+\") as file:\n",
    "    file.write(\"fn,season,author\\n\")\n",
    "    for fn in nr:\n",
    "        author=\"baker\"\n",
    "        month=fn[3:6]\n",
    "        if(fn[-3:]==\"txt\"):\n",
    "            if(fn[0]==\"_\"):\n",
    "                author=\"markov\"\n",
    "                month = fn[4:7]\n",
    "            elif(fn[0]==\"-\"):\n",
    "                author=\"gpt-2\"\n",
    "                month = fn[4:7]\n",
    "            file.write(fn+\",\"+seasons[month]+\",\"+author+\"\\n\")\n",
    "    file.close()\n",
    "path_to_metadata='../corpora/peregrine/peregrine.csv'\n",
    "\n",
    "# Get the metadata for this corpus\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "df_meta = pd.read_csv(path_to_metadata).set_index('fn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dtm(text_folder,normalize=False):\n",
    "\n",
    "    # make an empty results list\n",
    "    all_results = []\n",
    "    \n",
    "    columns=[]\n",
    "    attrbs = ['max_sent_len','min_sent_len','mean_sent_len',\n",
    "             'sd_sent_len','num_words','rare_words_count']\n",
    "    columns.append('fn')\n",
    "    for att in attrbs:\n",
    "        columns.append(att)\n",
    "    \n",
    "    # for each filename\n",
    "    filenames=sorted(os.listdir(text_folder))\n",
    "    for fn in filenames:\n",
    "        if(fn[-3:]==\"txt\"):\n",
    "            text_result = {}\n",
    "            text_result[\"fn\"]=fn\n",
    "            #max sent length, min sent length, mean sent length, standard deviation on sent length, number of sents, number of words\n",
    "            text_result['max_sent_len']=sent_data(fn)[1][0]\n",
    "            text_result['min_sent_len']=sent_data(fn)[1][1]\n",
    "            text_result['mean_sent_len']=sent_data(fn)[1][2]\n",
    "            text_result['sd_sent_len']=sent_data(fn)[1][3]\n",
    "            text_result['num_words']=sent_data(fn)[1][4]\n",
    "            text_result['rare_words_count'] = sent_data(fn)[1][5]\n",
    "            all_results.append(text_result)\n",
    "            \n",
    "\n",
    "    \n",
    "    # Make dataframe\n",
    "    df = pd.DataFrame(all_results, columns=columns).set_index('fn').fillna(0)\n",
    "    \n",
    "    # return dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Markovifies all files </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in os.listdir(text_folder):\n",
    "    if(fn[0] not in [\"_\",\"-\"] and fn[-3:]==\"txt\"):\n",
    "        markovify(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>author</th>\n",
       "      <th>max_sent_len</th>\n",
       "      <th>min_sent_len</th>\n",
       "      <th>mean_sent_len</th>\n",
       "      <th>sd_sent_len</th>\n",
       "      <th>num_words</th>\n",
       "      <th>rare_words_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00_oct-1.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>13.213115</td>\n",
       "      <td>6.606293</td>\n",
       "      <td>806</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_oct-3.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.918694</td>\n",
       "      <td>310</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02_oct-5.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>14.309524</td>\n",
       "      <td>7.651605</td>\n",
       "      <td>601</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03_oct-7.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>15.488372</td>\n",
       "      <td>8.439586</td>\n",
       "      <td>666</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04_oct-8.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>4.550811</td>\n",
       "      <td>392</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05_oct-9.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>5.843189</td>\n",
       "      <td>364</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06_oct-12.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>14.035714</td>\n",
       "      <td>5.133797</td>\n",
       "      <td>786</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07_oct-14.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.291757</td>\n",
       "      <td>290</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08_oct-15.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>17.185185</td>\n",
       "      <td>8.515942</td>\n",
       "      <td>464</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09_oct-16.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>16.840000</td>\n",
       "      <td>6.466405</td>\n",
       "      <td>421</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_77_mar-23.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>17.961538</td>\n",
       "      <td>6.790722</td>\n",
       "      <td>1868</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_78_mar-25.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>17.596774</td>\n",
       "      <td>7.122114</td>\n",
       "      <td>1091</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_79_mar-27.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>17.705128</td>\n",
       "      <td>6.324776</td>\n",
       "      <td>1381</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_80_mar-28.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>17.460000</td>\n",
       "      <td>7.442338</td>\n",
       "      <td>1746</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_81_mar-29.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>18.313433</td>\n",
       "      <td>6.565875</td>\n",
       "      <td>1227</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_82_mar-30.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>19.105263</td>\n",
       "      <td>7.433174</td>\n",
       "      <td>363</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_83_mar-31.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>16.170732</td>\n",
       "      <td>6.164028</td>\n",
       "      <td>663</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_84_apr-2.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>15.848485</td>\n",
       "      <td>6.372865</td>\n",
       "      <td>523</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_85_apr-3.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>16.724138</td>\n",
       "      <td>5.542292</td>\n",
       "      <td>970</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_86_apr-4.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>16.342466</td>\n",
       "      <td>6.436665</td>\n",
       "      <td>1193</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                season  author  max_sent_len  min_sent_len  mean_sent_len  \\\n",
       "fn                                                                          \n",
       "00_oct-1.txt      fall   baker            28             2      13.213115   \n",
       "01_oct-3.txt      fall   baker            20             2      10.000000   \n",
       "02_oct-5.txt      fall   baker            38             3      14.309524   \n",
       "03_oct-7.txt      fall   baker            44             2      15.488372   \n",
       "04_oct-8.txt      fall   baker            18             2      10.888889   \n",
       "05_oct-9.txt      fall   baker            26             2      13.000000   \n",
       "06_oct-12.txt     fall   baker            26             4      14.035714   \n",
       "07_oct-14.txt     fall   baker            26             4      10.000000   \n",
       "08_oct-15.txt     fall   baker            37             3      17.185185   \n",
       "09_oct-16.txt     fall   baker            36             7      16.840000   \n",
       "...                ...     ...           ...           ...            ...   \n",
       "_77_mar-23.txt  spring  markov            42             5      17.961538   \n",
       "_78_mar-25.txt  spring  markov            37             5      17.596774   \n",
       "_79_mar-27.txt  spring  markov            36             8      17.705128   \n",
       "_80_mar-28.txt  spring  markov            38             5      17.460000   \n",
       "_81_mar-29.txt  spring  markov            39             7      18.313433   \n",
       "_82_mar-30.txt  spring  markov            34             5      19.105263   \n",
       "_83_mar-31.txt  spring  markov            28             5      16.170732   \n",
       "_84_apr-2.txt   spring  markov            33             5      15.848485   \n",
       "_85_apr-3.txt   spring  markov            35             6      16.724138   \n",
       "_86_apr-4.txt   spring  markov            30             5      16.342466   \n",
       "\n",
       "                sd_sent_len  num_words  rare_words_count  \n",
       "fn                                                        \n",
       "00_oct-1.txt       6.606293        806               228  \n",
       "01_oct-3.txt       4.918694        310                82  \n",
       "02_oct-5.txt       7.651605        601               172  \n",
       "03_oct-7.txt       8.439586        666               159  \n",
       "04_oct-8.txt       4.550811        392               115  \n",
       "05_oct-9.txt       5.843189        364               103  \n",
       "06_oct-12.txt      5.133797        786               207  \n",
       "07_oct-14.txt      6.291757        290               101  \n",
       "08_oct-15.txt      8.515942        464               144  \n",
       "09_oct-16.txt      6.466405        421               120  \n",
       "...                     ...        ...               ...  \n",
       "_77_mar-23.txt     6.790722       1868               458  \n",
       "_78_mar-25.txt     7.122114       1091               274  \n",
       "_79_mar-27.txt     6.324776       1381               347  \n",
       "_80_mar-28.txt     7.442338       1746               445  \n",
       "_81_mar-29.txt     6.565875       1227               293  \n",
       "_82_mar-30.txt     7.433174        363                79  \n",
       "_83_mar-31.txt     6.164028        663               145  \n",
       "_84_apr-2.txt      6.372865        523               128  \n",
       "_85_apr-3.txt      5.542292        970               232  \n",
       "_86_apr-4.txt      6.436665       1193               288  \n",
       "\n",
       "[174 rows x 8 columns]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm = make_dtm(text_folder,normalize=True)\n",
    "dtm_meta=df_meta.merge(dtm,on='fn')\n",
    "dtm_meta = dtm_meta[dtm_meta.author !=\"gpt-2\"]\n",
    "dtm_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_sent_len</th>\n",
       "      <th>min_sent_len</th>\n",
       "      <th>mean_sent_len</th>\n",
       "      <th>sd_sent_len</th>\n",
       "      <th>num_words</th>\n",
       "      <th>rare_words_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baker</th>\n",
       "      <td>36.080460</td>\n",
       "      <td>3.885057</td>\n",
       "      <td>15.250972</td>\n",
       "      <td>7.412125</td>\n",
       "      <td>591.367816</td>\n",
       "      <td>155.310345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>markov</th>\n",
       "      <td>31.574713</td>\n",
       "      <td>6.448276</td>\n",
       "      <td>17.151927</td>\n",
       "      <td>5.992699</td>\n",
       "      <td>667.862069</td>\n",
       "      <td>169.206897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        max_sent_len  min_sent_len  mean_sent_len  sd_sent_len   num_words  \\\n",
       "author                                                                       \n",
       "baker      36.080460      3.885057      15.250972     7.412125  591.367816   \n",
       "markov     31.574713      6.448276      17.151927     5.992699  667.862069   \n",
       "\n",
       "        rare_words_count  \n",
       "author                    \n",
       "baker         155.310345  \n",
       "markov        169.206897  "
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_meta.groupby('author').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sents(fn):\n",
    "    data = sent_data(fn)[0]\n",
    "    num_sents = sent_data(fn)[1][6]\n",
    "    plt.bar(range(1,num_sents+1),data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_sent_len, min_sent_len, mean_sent_len, sd_sent_len,num_words,rare_words_count,num_sents\n",
      "[34, 3, 15.555555555555555, 7.88967132270077, 280, 72, 18]\n",
      "[25, 5, 15.277777777777779, 5.838621941249451, 275, 75, 18]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_date = \"43_dec-18.txt\"\n",
    "#markovify(test_date)\n",
    "print(\"max_sent_len, min_sent_len, mean_sent_len, sd_sent_len,num_words,rare_words_count,num_sents\")\n",
    "print(sent_data(test_date)[1])\n",
    "print(sent_data(\"_\"+test_date)[1])\n",
    "plot_sents(test_date)\n",
    "plot_sents(\"_\"+test_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> GRAPH SECTION </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_data(fn,verbose=True):\n",
    "    g = graph_dict[fn[:-4]]\n",
    "    d = dict(nx.degree(g))\n",
    "    max_degree = max(d.values())\n",
    "    hubs = sorted(zip(d.values(),d.keys()), reverse=True)[:3]\n",
    "    hubs_deg = hubs[0][0]+hubs[1][0]+hubs[2][0]\n",
    "    loss=g.number_of_edges()+1-dtm_meta.at[fn,\"num_words\"]\n",
    "    diameter = nx.diameter(g)\n",
    "    center = nx.center(g)\n",
    "    clustering = nx.average_clustering(g)\n",
    "    #closeness = nx.closeness_centrality(g).values()\n",
    "    dom_set = nx.dominating_set(g)\n",
    "    try:\n",
    "        max_ind = nx.maximal_independent_set(g)\n",
    "    except:\n",
    "        max_ind = {}\n",
    "    if(verbose):\n",
    "        print(\"hubs:\",hubs)\n",
    "        print(\"hubs_deg_sum:\", hubs_deg)\n",
    "        print(\"Loss:\",loss)\n",
    "        print(\"Diameter:\",diameter)\n",
    "        print(\"Center nodes:\",center)\n",
    "        print(\"Average clustering:\", clustering)\n",
    "        print(\"Dominating set:\",dom_set)\n",
    "        print(\"Dominating set length:\",len(dom_set))\n",
    "        print(\"Maximal independent set:\",max_ind)\n",
    "        print(\"Maximal independent set length:\",len(max_ind))\n",
    "    return([hubs, hubs_deg, loss, diameter,center,len(center),clustering,dom_set,len(dom_set),max_ind,len(max_ind)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Makes graphs for all files in directory </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../corpora/peregrine/'\n",
    "filenames = os.listdir(path)\n",
    "graph_dict = {}\n",
    "for f in filenames:\n",
    "    if(f[-3:] == \"txt\" and f[0]!=\"-\"):\n",
    "        filetext = open(path+f, \"r\").read()\n",
    "        graph_dict[f[:-4]]=makegraph(getsents(filetext))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Makes graphs for all files in directory </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph_dtm(text_folder,normalize=False):\n",
    "\n",
    "    # make an empty results list\n",
    "    all_results = []\n",
    "    \n",
    "    columns=[]\n",
    "\n",
    "    attrbs = ['hubs', 'hubs_deg_sum','loss','diameter',\n",
    "             'center', 'center_len','clustering','dom_set','len_dom_set','indep_set', 'len_indep_set']\n",
    "    columns.append('fn')\n",
    "    for att in attrbs:\n",
    "        columns.append(att)\n",
    "    \n",
    "    # for each filename\n",
    "    filenames=sorted(os.listdir(text_folder))\n",
    "    for fn in filenames:\n",
    "        if(fn[-3:]==\"txt\"):\n",
    "            text_result = {}\n",
    "            text_result[\"fn\"]=fn\n",
    "            gd = graph_data(fn, False)\n",
    "            \n",
    "            text_result['hubs']=gd[0]\n",
    "            text_result['hubs_deg_sum']=gd[1]\n",
    "            text_result['loss']=gd[2]\n",
    "            text_result['diameter']=gd[3]\n",
    "            text_result['center']=gd[4]\n",
    "            text_result['center_len'] = gd[5]\n",
    "            text_result['clustering']=gd[6]\n",
    "            text_result['dom_set']=gd[7]\n",
    "            text_result['len_dom_set']=gd[8]\n",
    "            text_result['indep_set']=gd[9]\n",
    "            text_result['len_indep_set']=gd[10]\n",
    "            all_results.append(text_result)\n",
    "            \n",
    "    \n",
    "    # Make dataframe\n",
    "    df = pd.DataFrame(all_results, columns=columns).set_index('fn').fillna(0)\n",
    "    \n",
    "    # return dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>author</th>\n",
       "      <th>hubs</th>\n",
       "      <th>hubs_deg_sum</th>\n",
       "      <th>loss</th>\n",
       "      <th>diameter</th>\n",
       "      <th>center</th>\n",
       "      <th>center_len</th>\n",
       "      <th>clustering</th>\n",
       "      <th>dom_set</th>\n",
       "      <th>len_dom_set</th>\n",
       "      <th>indep_set</th>\n",
       "      <th>len_indep_set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00_oct-1.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(12, sky), (12, jay), (12, hawk)]</td>\n",
       "      <td>36</td>\n",
       "      <td>-358</td>\n",
       "      <td>14</td>\n",
       "      <td>[sky, alder, river, hawk, water, watching, bli...</td>\n",
       "      <td>31</td>\n",
       "      <td>0.010929</td>\n",
       "      <td>{seldom, swept, perch, rest, mask, as, breakin...</td>\n",
       "      <td>151</td>\n",
       "      <td>[go, oak, hissed, watched, fovea, watching, ar...</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_oct-3.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(12, wader), (11, beach), (10, sea)]</td>\n",
       "      <td>33</td>\n",
       "      <td>-112</td>\n",
       "      <td>14</td>\n",
       "      <td>[sun, sea, flashing, salting, wader, white, be...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{slashed, sable, preening, cooling, could, leg...</td>\n",
       "      <td>69</td>\n",
       "      <td>[ringer, hundred, rose, wader, far, shimmering...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02_oct-5.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(12, wing), (10, long), (9, hawk)]</td>\n",
       "      <td>31</td>\n",
       "      <td>-264</td>\n",
       "      <td>13</td>\n",
       "      <td>[orchard]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>{rain, goldfinch, hawk, rain-smoked, separate,...</td>\n",
       "      <td>113</td>\n",
       "      <td>[small, red-brown, a, wafting, wooded, spun, c...</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03_oct-7.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(14, wing), (8, peregrine), (6, tail)]</td>\n",
       "      <td>28</td>\n",
       "      <td>-320</td>\n",
       "      <td>18</td>\n",
       "      <td>[foot, two, hundred, passing, twice, as, a, gr...</td>\n",
       "      <td>21</td>\n",
       "      <td>0.016136</td>\n",
       "      <td>{separate, swept, oddly, overhead, as, skylark...</td>\n",
       "      <td>122</td>\n",
       "      <td>[fur, beneath, surface, hour, effect, field, f...</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04_oct-8.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(15, wader), (12, like), (9, inland)]</td>\n",
       "      <td>36</td>\n",
       "      <td>-169</td>\n",
       "      <td>15</td>\n",
       "      <td>[flew, like, wader, small, facing]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.020095</td>\n",
       "      <td>{alert, hawk, stayed, harmless, many, brown, t...</td>\n",
       "      <td>77</td>\n",
       "      <td>[jostling, dangerous, formed, turning, stubble...</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05_oct-9.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(8, sun), (8, like), (6, jay)]</td>\n",
       "      <td>22</td>\n",
       "      <td>-153</td>\n",
       "      <td>17</td>\n",
       "      <td>[hid, shining, martin, flew, hawk]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{meat, hawk, stayed, dwindling, brown, pike, s...</td>\n",
       "      <td>77</td>\n",
       "      <td>[north, sunlight, swamp, saw, insipid, stay, f...</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06_oct-12.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(22, hawk), (16, crow), (12, like)]</td>\n",
       "      <td>50</td>\n",
       "      <td>-349</td>\n",
       "      <td>15</td>\n",
       "      <td>[away, peregrine, come, inland, estuary, hawk,...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>{beat, brown, tide, rest, gnarled, as, eleven,...</td>\n",
       "      <td>140</td>\n",
       "      <td>[flinging, rising, wader, shark, swarm, quench...</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07_oct-14.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(14, water), (8, peregrine), (8, godwit)]</td>\n",
       "      <td>30</td>\n",
       "      <td>-76</td>\n",
       "      <td>20</td>\n",
       "      <td>[white, glinting, water, grey, plover, seldom,...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>{seldom, sadness, zostera, dwindling, sneezing...</td>\n",
       "      <td>80</td>\n",
       "      <td>[insistent, widening, shrill, rafter, revolve,...</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08_oct-15.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(10, peregrine), (10, flew), (10, falcon)]</td>\n",
       "      <td>30</td>\n",
       "      <td>-210</td>\n",
       "      <td>18</td>\n",
       "      <td>[peregrine, tiercel, falcon, quicker, plumage]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>{hawk, many, brown, roost, a, gather, quickly,...</td>\n",
       "      <td>91</td>\n",
       "      <td>[angle, rush, falcon, true, circle, jackdaw, t...</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09_oct-16.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(10, spray), (8, water), (8, sky)]</td>\n",
       "      <td>26</td>\n",
       "      <td>-181</td>\n",
       "      <td>17</td>\n",
       "      <td>[spray, leapt, wave, along, shingle, ridge, fa...</td>\n",
       "      <td>18</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>{slashed, hawk, splayed, grass, brown, diminis...</td>\n",
       "      <td>83</td>\n",
       "      <td>[dusk, clearly, long, tide, smoke, outpouring,...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_77_mar-23.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(20, hawk), (20, flew), (19, sun)]</td>\n",
       "      <td>59</td>\n",
       "      <td>-1032</td>\n",
       "      <td>11</td>\n",
       "      <td>[went]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014082</td>\n",
       "      <td>{rain, beat, cart, sea, sank, perch, migrating...</td>\n",
       "      <td>230</td>\n",
       "      <td>[soared, say, hovering, kept, irritating, dead...</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_78_mar-25.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(15, flew), (12, across), (11, sun)]</td>\n",
       "      <td>38</td>\n",
       "      <td>-592</td>\n",
       "      <td>12</td>\n",
       "      <td>[slowly, hawk, went, back, sun, jerked, yard, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.015376</td>\n",
       "      <td>{sprayed, cart, sheltered, stayed, sank, many,...</td>\n",
       "      <td>145</td>\n",
       "      <td>[marsh, close, afloat, spiralled, line, within...</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_79_mar-27.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(16, wind), (16, tree), (16, sun)]</td>\n",
       "      <td>48</td>\n",
       "      <td>-785</td>\n",
       "      <td>13</td>\n",
       "      <td>[along]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013242</td>\n",
       "      <td>{beat, cart, switchbacking, sea, many, perch, ...</td>\n",
       "      <td>164</td>\n",
       "      <td>[drifting, sailed, began, head, wood, brightne...</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_80_mar-28.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(32, flew), (21, wind), (18, tree)]</td>\n",
       "      <td>71</td>\n",
       "      <td>-945</td>\n",
       "      <td>12</td>\n",
       "      <td>[flew]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012865</td>\n",
       "      <td>{rain, muscle, beat, cart, sheltered, swept, s...</td>\n",
       "      <td>207</td>\n",
       "      <td>[much, larger, blossom, beneath, stream, woodp...</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_81_mar-29.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(14, wing), (13, tree), (12, like)]</td>\n",
       "      <td>39</td>\n",
       "      <td>-647</td>\n",
       "      <td>14</td>\n",
       "      <td>[would, come, one, twig, wing, hawk, like, gen...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.016696</td>\n",
       "      <td>{nerve, cart, sheltered, swept, sea, many, per...</td>\n",
       "      <td>181</td>\n",
       "      <td>[however, turned, standing, moulded, bill, fig...</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_82_mar-30.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(12, wind), (6, away), (5, as)]</td>\n",
       "      <td>23</td>\n",
       "      <td>-175</td>\n",
       "      <td>22</td>\n",
       "      <td>[mist, stir, looking, intently, grass, long, c...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.007643</td>\n",
       "      <td>{rain, corn, featureless, gently, branch, dusk...</td>\n",
       "      <td>72</td>\n",
       "      <td>[sunk, keep, away, smell, orchard, beating, th...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_83_mar-31.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(13, flew), (8, wing), (8, suddenly)]</td>\n",
       "      <td>29</td>\n",
       "      <td>-319</td>\n",
       "      <td>15</td>\n",
       "      <td>[a, though, high, spring, suddenly, fluttered,...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.013127</td>\n",
       "      <td>{sing, beat, sheltered, many, fluttering, tide...</td>\n",
       "      <td>119</td>\n",
       "      <td>[white, gone, calling, sodden, see, occasional...</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_84_apr-2.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(9, oak), (8, long), (8, like)]</td>\n",
       "      <td>25</td>\n",
       "      <td>-268</td>\n",
       "      <td>16</td>\n",
       "      <td>[flew, towards, southern, long, elm, sea-wall,...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>{slackened, hawk, cart, grass, brown, graceful...</td>\n",
       "      <td>89</td>\n",
       "      <td>[bedraggled, still, interest, blackbird, low, ...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_85_apr-3.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(19, flew), (13, sun), (11, away)]</td>\n",
       "      <td>43</td>\n",
       "      <td>-505</td>\n",
       "      <td>15</td>\n",
       "      <td>[brook, high, flew, ridge, wing, across, sun, ...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.017359</td>\n",
       "      <td>{many, perch, dull, graceful, tide, barn, skyl...</td>\n",
       "      <td>151</td>\n",
       "      <td>[peregrine, feathery, watching, close, dived, ...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_86_apr-4.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(16, long), (15, tree), (15, flew)]</td>\n",
       "      <td>46</td>\n",
       "      <td>-658</td>\n",
       "      <td>10</td>\n",
       "      <td>[tree, long, perched, elm, grass, back]</td>\n",
       "      <td>6</td>\n",
       "      <td>0.014189</td>\n",
       "      <td>{sprayed, beat, sea, stayed, many, perch, grac...</td>\n",
       "      <td>173</td>\n",
       "      <td>[beat, like, meet, sparrow, speed, soar, curio...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                season  author                                         hubs  \\\n",
       "fn                                                                            \n",
       "00_oct-1.txt      fall   baker           [(12, sky), (12, jay), (12, hawk)]   \n",
       "01_oct-3.txt      fall   baker        [(12, wader), (11, beach), (10, sea)]   \n",
       "02_oct-5.txt      fall   baker          [(12, wing), (10, long), (9, hawk)]   \n",
       "03_oct-7.txt      fall   baker      [(14, wing), (8, peregrine), (6, tail)]   \n",
       "04_oct-8.txt      fall   baker       [(15, wader), (12, like), (9, inland)]   \n",
       "05_oct-9.txt      fall   baker              [(8, sun), (8, like), (6, jay)]   \n",
       "06_oct-12.txt     fall   baker         [(22, hawk), (16, crow), (12, like)]   \n",
       "07_oct-14.txt     fall   baker   [(14, water), (8, peregrine), (8, godwit)]   \n",
       "08_oct-15.txt     fall   baker  [(10, peregrine), (10, flew), (10, falcon)]   \n",
       "09_oct-16.txt     fall   baker          [(10, spray), (8, water), (8, sky)]   \n",
       "...                ...     ...                                          ...   \n",
       "_77_mar-23.txt  spring  markov          [(20, hawk), (20, flew), (19, sun)]   \n",
       "_78_mar-25.txt  spring  markov        [(15, flew), (12, across), (11, sun)]   \n",
       "_79_mar-27.txt  spring  markov          [(16, wind), (16, tree), (16, sun)]   \n",
       "_80_mar-28.txt  spring  markov         [(32, flew), (21, wind), (18, tree)]   \n",
       "_81_mar-29.txt  spring  markov         [(14, wing), (13, tree), (12, like)]   \n",
       "_82_mar-30.txt  spring  markov             [(12, wind), (6, away), (5, as)]   \n",
       "_83_mar-31.txt  spring  markov       [(13, flew), (8, wing), (8, suddenly)]   \n",
       "_84_apr-2.txt   spring  markov             [(9, oak), (8, long), (8, like)]   \n",
       "_85_apr-3.txt   spring  markov          [(19, flew), (13, sun), (11, away)]   \n",
       "_86_apr-4.txt   spring  markov         [(16, long), (15, tree), (15, flew)]   \n",
       "\n",
       "                hubs_deg_sum  loss  diameter  \\\n",
       "fn                                             \n",
       "00_oct-1.txt              36  -358        14   \n",
       "01_oct-3.txt              33  -112        14   \n",
       "02_oct-5.txt              31  -264        13   \n",
       "03_oct-7.txt              28  -320        18   \n",
       "04_oct-8.txt              36  -169        15   \n",
       "05_oct-9.txt              22  -153        17   \n",
       "06_oct-12.txt             50  -349        15   \n",
       "07_oct-14.txt             30   -76        20   \n",
       "08_oct-15.txt             30  -210        18   \n",
       "09_oct-16.txt             26  -181        17   \n",
       "...                      ...   ...       ...   \n",
       "_77_mar-23.txt            59 -1032        11   \n",
       "_78_mar-25.txt            38  -592        12   \n",
       "_79_mar-27.txt            48  -785        13   \n",
       "_80_mar-28.txt            71  -945        12   \n",
       "_81_mar-29.txt            39  -647        14   \n",
       "_82_mar-30.txt            23  -175        22   \n",
       "_83_mar-31.txt            29  -319        15   \n",
       "_84_apr-2.txt             25  -268        16   \n",
       "_85_apr-3.txt             43  -505        15   \n",
       "_86_apr-4.txt             46  -658        10   \n",
       "\n",
       "                                                           center  center_len  \\\n",
       "fn                                                                              \n",
       "00_oct-1.txt    [sky, alder, river, hawk, water, watching, bli...          31   \n",
       "01_oct-3.txt    [sun, sea, flashing, salting, wader, white, be...          26   \n",
       "02_oct-5.txt                                            [orchard]           1   \n",
       "03_oct-7.txt    [foot, two, hundred, passing, twice, as, a, gr...          21   \n",
       "04_oct-8.txt                   [flew, like, wader, small, facing]           5   \n",
       "05_oct-9.txt                   [hid, shining, martin, flew, hawk]           5   \n",
       "06_oct-12.txt   [away, peregrine, come, inland, estuary, hawk,...          16   \n",
       "07_oct-14.txt   [white, glinting, water, grey, plover, seldom,...          11   \n",
       "08_oct-15.txt      [peregrine, tiercel, falcon, quicker, plumage]           5   \n",
       "09_oct-16.txt   [spray, leapt, wave, along, shingle, ridge, fa...          18   \n",
       "...                                                           ...         ...   \n",
       "_77_mar-23.txt                                             [went]           1   \n",
       "_78_mar-25.txt  [slowly, hawk, went, back, sun, jerked, yard, ...          12   \n",
       "_79_mar-27.txt                                            [along]           1   \n",
       "_80_mar-28.txt                                             [flew]           1   \n",
       "_81_mar-29.txt  [would, come, one, twig, wing, hawk, like, gen...          16   \n",
       "_82_mar-30.txt  [mist, stir, looking, intently, grass, long, c...          10   \n",
       "_83_mar-31.txt  [a, though, high, spring, suddenly, fluttered,...          20   \n",
       "_84_apr-2.txt   [flew, towards, southern, long, elm, sea-wall,...          11   \n",
       "_85_apr-3.txt   [brook, high, flew, ridge, wing, across, sun, ...          25   \n",
       "_86_apr-4.txt             [tree, long, perched, elm, grass, back]           6   \n",
       "\n",
       "                clustering                                            dom_set  \\\n",
       "fn                                                                              \n",
       "00_oct-1.txt      0.010929  {seldom, swept, perch, rest, mask, as, breakin...   \n",
       "01_oct-3.txt      0.000000  {slashed, sable, preening, cooling, could, leg...   \n",
       "02_oct-5.txt      0.004715  {rain, goldfinch, hawk, rain-smoked, separate,...   \n",
       "03_oct-7.txt      0.016136  {separate, swept, oddly, overhead, as, skylark...   \n",
       "04_oct-8.txt      0.020095  {alert, hawk, stayed, harmless, many, brown, t...   \n",
       "05_oct-9.txt      0.000000  {meat, hawk, stayed, dwindling, brown, pike, s...   \n",
       "06_oct-12.txt     0.005779  {beat, brown, tide, rest, gnarled, as, eleven,...   \n",
       "07_oct-14.txt     0.007088  {seldom, sadness, zostera, dwindling, sneezing...   \n",
       "08_oct-15.txt     0.008955  {hawk, many, brown, roost, a, gather, quickly,...   \n",
       "09_oct-16.txt     0.002646  {slashed, hawk, splayed, grass, brown, diminis...   \n",
       "...                    ...                                                ...   \n",
       "_77_mar-23.txt    0.014082  {rain, beat, cart, sea, sank, perch, migrating...   \n",
       "_78_mar-25.txt    0.015376  {sprayed, cart, sheltered, stayed, sank, many,...   \n",
       "_79_mar-27.txt    0.013242  {beat, cart, switchbacking, sea, many, perch, ...   \n",
       "_80_mar-28.txt    0.012865  {rain, muscle, beat, cart, sheltered, swept, s...   \n",
       "_81_mar-29.txt    0.016696  {nerve, cart, sheltered, swept, sea, many, per...   \n",
       "_82_mar-30.txt    0.007643  {rain, corn, featureless, gently, branch, dusk...   \n",
       "_83_mar-31.txt    0.013127  {sing, beat, sheltered, many, fluttering, tide...   \n",
       "_84_apr-2.txt     0.002600  {slackened, hawk, cart, grass, brown, graceful...   \n",
       "_85_apr-3.txt     0.017359  {many, perch, dull, graceful, tide, barn, skyl...   \n",
       "_86_apr-4.txt     0.014189  {sprayed, beat, sea, stayed, many, perch, grac...   \n",
       "\n",
       "                len_dom_set  \\\n",
       "fn                            \n",
       "00_oct-1.txt            151   \n",
       "01_oct-3.txt             69   \n",
       "02_oct-5.txt            113   \n",
       "03_oct-7.txt            122   \n",
       "04_oct-8.txt             77   \n",
       "05_oct-9.txt             77   \n",
       "06_oct-12.txt           140   \n",
       "07_oct-14.txt            80   \n",
       "08_oct-15.txt            91   \n",
       "09_oct-16.txt            83   \n",
       "...                     ...   \n",
       "_77_mar-23.txt          230   \n",
       "_78_mar-25.txt          145   \n",
       "_79_mar-27.txt          164   \n",
       "_80_mar-28.txt          207   \n",
       "_81_mar-29.txt          181   \n",
       "_82_mar-30.txt           72   \n",
       "_83_mar-31.txt          119   \n",
       "_84_apr-2.txt            89   \n",
       "_85_apr-3.txt           151   \n",
       "_86_apr-4.txt           173   \n",
       "\n",
       "                                                        indep_set  \\\n",
       "fn                                                                  \n",
       "00_oct-1.txt    [go, oak, hissed, watched, fovea, watching, ar...   \n",
       "01_oct-3.txt    [ringer, hundred, rose, wader, far, shimmering...   \n",
       "02_oct-5.txt    [small, red-brown, a, wafting, wooded, spun, c...   \n",
       "03_oct-7.txt    [fur, beneath, surface, hour, effect, field, f...   \n",
       "04_oct-8.txt    [jostling, dangerous, formed, turning, stubble...   \n",
       "05_oct-9.txt    [north, sunlight, swamp, saw, insipid, stay, f...   \n",
       "06_oct-12.txt   [flinging, rising, wader, shark, swarm, quench...   \n",
       "07_oct-14.txt   [insistent, widening, shrill, rafter, revolve,...   \n",
       "08_oct-15.txt   [angle, rush, falcon, true, circle, jackdaw, t...   \n",
       "09_oct-16.txt   [dusk, clearly, long, tide, smoke, outpouring,...   \n",
       "...                                                           ...   \n",
       "_77_mar-23.txt  [soared, say, hovering, kept, irritating, dead...   \n",
       "_78_mar-25.txt  [marsh, close, afloat, spiralled, line, within...   \n",
       "_79_mar-27.txt  [drifting, sailed, began, head, wood, brightne...   \n",
       "_80_mar-28.txt  [much, larger, blossom, beneath, stream, woodp...   \n",
       "_81_mar-29.txt  [however, turned, standing, moulded, bill, fig...   \n",
       "_82_mar-30.txt  [sunk, keep, away, smell, orchard, beating, th...   \n",
       "_83_mar-31.txt  [white, gone, calling, sodden, see, occasional...   \n",
       "_84_apr-2.txt   [bedraggled, still, interest, blackbird, low, ...   \n",
       "_85_apr-3.txt   [peregrine, feathery, watching, close, dived, ...   \n",
       "_86_apr-4.txt   [beat, like, meet, sparrow, speed, soar, curio...   \n",
       "\n",
       "                len_indep_set  \n",
       "fn                             \n",
       "00_oct-1.txt              154  \n",
       "01_oct-3.txt               72  \n",
       "02_oct-5.txt              119  \n",
       "03_oct-7.txt              120  \n",
       "04_oct-8.txt               79  \n",
       "05_oct-9.txt               78  \n",
       "06_oct-12.txt             142  \n",
       "07_oct-14.txt              79  \n",
       "08_oct-15.txt              88  \n",
       "09_oct-16.txt              81  \n",
       "...                       ...  \n",
       "_77_mar-23.txt            233  \n",
       "_78_mar-25.txt            151  \n",
       "_79_mar-27.txt            166  \n",
       "_80_mar-28.txt            214  \n",
       "_81_mar-29.txt            171  \n",
       "_82_mar-30.txt             70  \n",
       "_83_mar-31.txt            118  \n",
       "_84_apr-2.txt              91  \n",
       "_85_apr-3.txt             155  \n",
       "_86_apr-4.txt             155  \n",
       "\n",
       "[174 rows x 13 columns]"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdtm = make_graph_dtm(text_folder,normalize=True)\n",
    "gdtm_meta=df_meta.merge(gdtm,on='fn')\n",
    "#gdtm_meta = gdtm_meta[dtm_meta.author !=\"gpt-2\"]\n",
    "gdtm_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hubs_deg_sum</th>\n",
       "      <th>loss</th>\n",
       "      <th>diameter</th>\n",
       "      <th>center_len</th>\n",
       "      <th>clustering</th>\n",
       "      <th>len_dom_set</th>\n",
       "      <th>len_indep_set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baker</th>\n",
       "      <td>33.275862</td>\n",
       "      <td>-269.804598</td>\n",
       "      <td>17.701149</td>\n",
       "      <td>6.988506</td>\n",
       "      <td>0.011279</td>\n",
       "      <td>107.747126</td>\n",
       "      <td>108.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>markov</th>\n",
       "      <td>31.678161</td>\n",
       "      <td>-344.609195</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>7.310345</td>\n",
       "      <td>0.011902</td>\n",
       "      <td>105.080460</td>\n",
       "      <td>104.885057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        hubs_deg_sum        loss   diameter  center_len  clustering  \\\n",
       "author                                                                \n",
       "baker      33.275862 -269.804598  17.701149    6.988506    0.011279   \n",
       "markov     31.678161 -344.609195  16.666667    7.310345    0.011902   \n",
       "\n",
       "        len_dom_set  len_indep_set  \n",
       "author                              \n",
       "baker    107.747126     108.620690  \n",
       "markov   105.080460     104.885057  "
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdtm_meta.groupby('author').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hubs: [(12, 'peregrine'), (10, 'white'), (10, 'hawk')]\n",
      "hubs_deg_sum: 32\n",
      "Loss: -517\n",
      "Diameter: 13\n",
      "Center nodes: ['hawk', 'as', 'a', 'sea', 'must', 'glided', 'suddenly', 'north', 'rushed']\n",
      "Average clustering: 0.008694303663815859\n",
      "Dominating set: {'glare', 'plunge', 'pursue', 'sea', 'many', 'perch', 'absorbed', 'brown', 'echo', 'ride', 'summer', 'reflective', 'pierced', 'as', 'puff', 'pasture', 'glared', 'frost', 'around', 'north', 'tree', 'impelling', 'life', 'song', 'pond', 'waning', 'small', 'peacefully', 'breast', 'warm', 'six', 'killed', 'downstream', 'straight', 'swooped', 'line', 'furiously', 'muscular', 'sombre', 'jerked', 'flight', 'hide', 'higher', 'fragment', 'throughout', 'west', 'gold', 'oclock', 'saw', 'unrelenting', 'without', 'seen', 'remains', 'fire', 'mile', 'though', 'could', 'lost', 'leaf', 'damp', 'tractor', 'flew', 'sunlight', 'clustered', 'past', 'left', 'road', 'ice', 'ploughing', 'swung', 'sweeping', 'boomed', 'east', 'dust', 'counter-shading', 'force', 'across', 'lanced', 'waiting', 'clear', 'dying', 'rising', 'wraith-like', 'round', 'welled', 'head', 'nowhere', 'flesh', 'tremendous', 'beneath', 'sound', 'going', 'partridge', 'feeding', 'blue-grey', 'deeply', 'minute', 'straining', 'gleam', 'behind', 'crenellation', 'pigeon', 'river', 'blade', 'hung', 'descended', 'hour', 'circle', 'post', 'mud', 'drifted', 'beak', 'alternately', 'second', 'soared', 'shot', 'lashing', 'thirty', 'verge', 'became', 'smooth', 'floated', 'day', 'intervening', 'jackdaw', 'stuck', 'island', 'together', 'stifling', 'circling', 'end', 'darkness', 'hidden', 'huddled', 'path', 'clouded', 'gaping', 'green', 'time', 'fast', 'high', 'spread', 'reflected', 'fruit'}\n",
      "Dominating set length: 144\n",
      "Maximal independent set: ['farm', 'stared', 'floated', 'white-ringed', 'minute', 'fell', 'searching', 'head', 'song', 'ditch', 'air', 'grass', 'clustered', 'horizon', 'mile', 'calling', 'ahead', 'without', 'tremendous', 'blue', 'lost', 'thickness', 'still', 'made', 'slope', 'mallard', 'curved', 'many', 'downstream', 'dust', 'circling', 'un-melted', 'swooped', 'tree', 'day', 'unsubstantial', 'wing', 'past', 'bloody', 'gull', 'haze', 'soar', 'oclock', 'ground', 'soft', 'direction', 'squib', 'thirty', 'bent', 'clear', 'flight', 'straining', 'force', 'rested', 'furiously', 'deeply', 'fire', 'circle', 'plunged', 'welled', 'first', 'peregrine', 'shot', 'high', 'bright', 'reflected', 'hour', 'waiting', 'line', 'snow-drifted', 'descended', 'rose', 'thirteen', 'light', 'dead', 'gale', 'flickered', 'gold', 'pigeon', 'deep', 'pursue', 'rise', 'alternately', 'huddled', 'beneath', 'small', 'dying', 'sound', 'fragment', 'peacefully', 'glared', 'jerked', 'dark', 'till', 'hook', 'outwards', 'dream', 'told', 'crenellation', 'field', 'smooth', 'sunlight', 'west', 'lashing', 'frosted', 'a', 'sweeping', 'around', 'shade', 'clearer', 'shuddered', 'perch', 'waning', 'behind', 'suddenly', 'unrelenting', 'mud', 'scrub-covered', 'beak', 'leg', 'falling', 'hotter', 'cutting', 'year', 'throughout', 'left', 'together', 'life', 'night', 'foot', 'drifted', 'going', 'pale', 'six', 'clouded', 'full', 'fear', 'glare', 'gaping', 'flower-pot', 'partridge', 'bend', 'blown', 'feeding']\n",
      "Maximal independent set length: 144\n"
     ]
    }
   ],
   "source": [
    "checkfile=\"54_jan-25\"\n",
    "_g = graph_dict[\"_\"+checkfile]\n",
    "_gd = graph_data(\"_\"+checkfile+\".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hubs: [(24, 'snow'), (22, 'like'), (9, 'blood')]\n",
      "hubs_deg_sum: 55\n",
      "Loss: -301\n",
      "Diameter: 20\n",
      "Center nodes: ['like', 'moorhen', 'ice', 'diving', 'saw', 'coming', 'six', 'hare', 'crouched', 'together', 'hawthorn', 'bar', 'grey', 'pheasant', 'plunged', 'foot', 'pair', 'gaunt', 'hole', 'blood']\n",
      "Average clustering: 0.011057411559083798\n",
      "Dominating set: {'slithered', 'goldfinch', 'foot-deep', 'copper', 'loud', 'marrow', 'separate', 'many', 'pike', 'pierced', 'as', 'hate', 'skylark', 'spray', 'tremulously', 'low', 'hovered', 'camel', 'tower', 'glowing', 'north', 'tree', 'impelling', 'fiercely', 'way', 'trudged', 'waning', 'small', 'danced', 'torch-lit', 'fieldfare', 'moving', 'dragged', 'herring', 'foot', 'six', 'killed', 'contorting', 'hurtling', 'outer', 'fish-blood', 'brittle', 'turning', 'sloping', 'thin', 'cattle', 'men', 'apple', 'beside', 'threaded', 'open', 'torn', 'tangle', 'something', 'bill', 'torpedoed', 'adjective', 'brain', 'bar', 'burning', 'though', 'walked', 'fifteen', 'love', 'towards', 'clutched', 'lay', 'tilted', 'ran', 'hollowed', 'holly', 'transparent', 'hedge', 'weighing', 'pied', 'swam', 'hole', 'alpine', 'wren', 'across', 'tripping', 'snapping', 'dead', 'grate', 'meaningless', 'dark', 'crowded', 'perhaps', 'otter', 'treecreeper', 'still', 'southward', 'steep-rising', 'wraith-like', 'round', 'welled', 'gunfire', 'shrivelled', 'rook', 'hill', 'misty', 'woodpigeons', 'flowing', 'scrub-covered', 'richly', 'near', 'willow', 'inside', 'eyeless', 'freezing', 'fox', 'gleam', 'afternoon', 'stood', 'air', 'hand', 'plunged', 'surface', 'landed', 'diving', 'descended', 'circle', 'tooth', 'tame', 'tired', 'coracle', 'toy', 'purple', 'shaded', 'feather', 'tear', 'day', 'field', 'strange', 'together', 'seemed', 'circling', 'reed', 'breath', 'chipped', 'shrunken', 'perched', 'horrifying', 'coming', 'cold', 'fast', 'time', 'flycatcher', 'slat', 'pair', 'great'}\n",
      "Dominating set length: 151\n",
      "Maximal independent set: ['two', 'way', 'dragged', 'tear', 'tree', 'snapping', 'freezing', 'transparent', 'strange', 'bramble', 'song', 'grate', 'tired', 'ditch', 'flowing', 'crutch', 'trudged', 'roof', 'horizon', 'rook', 'dry', 'sky', 'sun', 'foot', 'upward', 'water', 'shimmer', 'feeding', 'useless', 'mind', 'hovered', 'time', 'unsubstantial', 'tripping', 'baying', 'fast', 'beautifully', 'crept', 'gull', 'saw', 'already', 'hand', 'big', 'hole', 'wagtail', 'surface', 'shaking', 'stale', 'steep-rising', 'belfry', 'sneaking', 'tooth', 'prey', 'pitched', 'field', 'wind', 'waning', 'horrifying', 'beside', 'frosty', 'cattle', 'farm', 'twining', 'killed', 'separate', 'desert', 'right', 'six', 'grebe', 'hollowed', 'outer', 'snipe', 'fox', 'corps', 'foot-deep', 'apple', 'tangle', 'chaffinch', 'meaningless', 'chattering', 'purple', 'holy', 'dying', 'small', 'towards', 'neck', 'torch-lit', 'spray', 'together', 'nothing', 'across', 'pipit', 'torpedoed', 'went', 'lay', 'still', 'lined', 'though', 'holly', 'weighing', 'town', 'left', 'frame', 'bar', 'toy', 'alpine', 'languidly', 'bill', 'round', 'half', 'thin', 'country', 'copper', 'welled', 'threaded', 'many', 'loud', 'gleam', 'feather', 'rafter', 'tilted', 'hill', 'plunged', 'billhook', 'calm', 'impelling', 'landed', 'shaded', 'shrivelled', 'stretch', 'hate', 'valley', 'flycatcher', 'church', 'pierced', 'scrub-covered', 'track', 'slithered', 'something', 'claw', 'stood', 'law', 'pair', 'clutched', 'fish-blood', 'hurtling', 'circle', 'ten', 'broke', 'cutting', 'reluctantly', 'turning', 'today', 'fat-bottomed', 'made', 'day']\n",
      "Maximal independent set length: 156\n"
     ]
    }
   ],
   "source": [
    "g = graph_dict[checkfile]\n",
    "gd = graph_data(checkfile+\".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"750px\"\n",
       "            src=\"graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a2e3df198>"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_graph3(_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"750px\"\n",
       "            src=\"graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a2c92ca58>"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_graph3(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concordance(text_folder,filename,word,width=100,lines=1000):\n",
    "    # Get the path\n",
    "    text_path = os.path.join(text_folder, filename)\n",
    "    print(text_path)\n",
    "\n",
    "    # Open the file\n",
    "    with open(text_path) as file:\n",
    "        text_txt=file.read()\n",
    "\n",
    "    # make nltk version of the text (useful for concordance)\n",
    "    import nltk\n",
    "    text_words = nltk.word_tokenize(text_txt)\n",
    "    text_nltk = nltk.text.Text(text_words)\n",
    "\n",
    "    # get concordance\n",
    "    text_nltk.concordance(word,width=width,lines=lines)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../corpora/peregrine/_52_jan-9.txt\n",
      "Displaying 1 of 1 matches:\n",
      "hundred woodpigeons clattered up from the mud , like damp squibs . None moved when I walked towards \n",
      "../corpora/peregrine/52_jan-9.txt\n",
      "Displaying 1 of 1 matches:\n",
      "awks . Their eyes see maps of black and white , like a crackle of silent film . The moving black is \n"
     ]
    }
   ],
   "source": [
    "concordance(text_folder,'_'+checkfile+\".txt\",\"like\")\n",
    "concordance(text_folder,checkfile+\".txt\",\"like\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
