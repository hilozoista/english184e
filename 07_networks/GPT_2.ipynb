{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pzxl1vYX-1kk"
   },
   "source": [
    "Setup:\n",
    "\n",
    "1) Make sure GPU is enabled, go to edit->notebook settings->Hardware Accelerator GPU\n",
    "\n",
    "2) Make a copy to your google drive, click on copy to drive in panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iW0abT07ZkhZ"
   },
   "source": [
    "Note: Colab will reset after 12 hours make sure to save your model checkpoints to google drive around 10-11 hours mark or before, then go to runtime->reset all runtimes. Now copy your train model back into colab and start training again from the previous checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iLXW02eIYpcB"
   },
   "source": [
    "clone and cd into repo, nshepperd's fork https://github.com/nshepperd/gpt-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ICYu3w9hIJkC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'gpt-2'...\n",
      "remote: Enumerating objects: 297, done.\u001b[K\n",
      "remote: Total 297 (delta 0), reused 0 (delta 0), pack-reused 297\u001b[K\n",
      "Receiving objects: 100% (297/297), 4.40 MiB | 19.91 MiB/s, done.\n",
      "Resolving deltas: 100% (163/163), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/nshepperd/gpt-2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6eEIs3ApZUVO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/SITPadmin/english184e/07_networks/gpt-2\n"
     ]
    }
   ],
   "source": [
    "cd gpt-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qtn1qZPgZLb0"
   },
   "source": [
    "Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "434oOx0bZH6J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fire>=0.1.3 (from -r requirements.txt (line 1))\n",
      "Collecting regex==2017.4.5 (from -r requirements.txt (line 2))\n",
      "Collecting requests==2.21.0 (from -r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl\n",
      "Collecting tqdm==4.31.1 (from -r requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl\n",
      "Collecting toposort==1.5 (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\n",
      "Collecting six (from fire>=0.1.3->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Collecting urllib3<1.25,>=1.21.1 (from requests==2.21.0->-r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/01/11/525b02e4acc0c747de8b6ccdab376331597c569c42ea66ab0a1dbd36eca2/urllib3-1.24.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2019.3.9)\n",
      "Collecting idna<2.9,>=2.5 (from requests==2.21.0->-r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl\n",
      "Collecting chardet<3.1.0,>=3.0.2 (from requests==2.21.0->-r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Installing collected packages: six, fire, regex, urllib3, idna, chardet, requests, tqdm, toposort\n",
      "Successfully installed chardet-3.0.4 fire-0.1.3 idna-2.8 regex-2017.4.5 requests-2.21.0 six-1.12.0 toposort-1.5 tqdm-4.31.1 urllib3-1.24.3\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WvUQhgK3PQ4L"
   },
   "source": [
    "Mount drive to access google drive for saving and accessing checkpoints later. Have to log in to your google account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FNpf6R4ahYSN"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o1hrgeKFYsuE"
   },
   "source": [
    "Download the model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A498TySgHYyF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.00kit [00:00, 672kit/s]                                                      \n",
      "Fetching encoder.json: 1.04Mit [00:00, 23.9Mit/s]                                                   \n",
      "Fetching hparams.json: 1.00kit [00:00, 713kit/s]                                                    \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:09, 54.5Mit/s]                                  \n",
      "Fetching model.ckpt.index: 6.00kit [00:00, 3.80Mit/s]                                               \n",
      "Fetching model.ckpt.meta: 472kit [00:00, 16.4Mit/s]                                                 \n",
      "Fetching vocab.bpe: 457kit [00:00, 15.1Mit/s]                                                       \n"
     ]
    }
   ],
   "source": [
    "!python3 download_model.py 117M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5UDpEGjfO8Q2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.00kit [00:00, 725kit/s]                                                      \n",
      "Fetching encoder.json: 1.04Mit [00:00, 23.6Mit/s]                                                   \n",
      "Fetching hparams.json: 1.00kit [00:00, 661kit/s]                                                    \n",
      "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:31, 45.7Mit/s]                                 \n",
      "Fetching model.ckpt.index: 11.0kit [00:00, 6.74Mit/s]                                               \n",
      "Fetching model.ckpt.meta: 927kit [00:00, 19.4Mit/s]                                                 \n",
      "Fetching vocab.bpe: 457kit [00:00, 16.9Mit/s]                                                       \n"
     ]
    }
   ],
   "source": [
    "!python3 download_model.py 345M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zq-YwRnNOBYO"
   },
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7oJPQtdLbbeK"
   },
   "outputs": [],
   "source": [
    "!export PYTHONIOENCODING=UTF-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0KzSbAvePgsI"
   },
   "source": [
    "Fetch checkpoints if you have them saved in google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cA2Wk7yIPmS6"
   },
   "outputs": [],
   "source": [
    "!cp -r /content/drive/My\\ Drive/checkpoint/ /content/gpt-2/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0p--9zwqQRTc"
   },
   "source": [
    "\n",
    "Let's get our train on! In this case the file is A Tale of Two Cities (Charles Dickens) from Project Gutenberg. To change the dataset GPT-2 models will fine-tune on, change this URL to another .txt file, and change corresponding part of the next cell. Note that you can use small datasets if you want but you will have to be sure not to run the fine-tuning for too long or you will overfit badly. Roughly, expect interesting results within minutes to hours in the 1-10s of megabyte ballpark, and below this you may want to stop the run early as fine-tuning can be very fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QOCvrs-DHvxa"
   },
   "outputs": [],
   "source": [
    "!wget https://www.gutenberg.org/files/98/98-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RfP7MFOxL6Ze"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting toposort\n",
      "  Using cached https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\n",
      "Installing collected packages: toposort\n",
      "Successfully installed toposort-1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install toposort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yPfJ5b3CQXqr"
   },
   "source": [
    "\n",
    "Start training, add --model_name '345M' to use 345 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pEn_ihcGI00T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-30 23:26:23.259243: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/SITPadmin/english184e/07_networks/gpt-2/src/sample.py:65: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/SITPadmin/english184e/07_networks/gpt-2/src/sample.py:70: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.random.categorical instead.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Loading checkpoint models/345M/model.ckpt\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "Loading dataset...\n",
      "0it [00:00, ?it/s]\n",
      "dataset has 0 tokens\n",
      "Training...\n",
      "Traceback (most recent call last):\n",
      "  File \"./train.py\", line 293, in <module>\n",
      "    main()\n",
      "  File \"./train.py\", line 271, in main\n",
      "    feed_dict={context: sample_batch()})\n",
      "  File \"./train.py\", line 247, in sample_batch\n",
      "    return [data_sampler.sample(1024) for _ in range(args.batch_size)]\n",
      "  File \"./train.py\", line 247, in <listcomp>\n",
      "    return [data_sampler.sample(1024) for _ in range(args.batch_size)]\n",
      "  File \"/Users/SITPadmin/english184e/07_networks/gpt-2/src/load_dataset.py\", line 74, in sample\n",
      "    self.chunks\n",
      "ZeroDivisionError: integer division or modulo by zero\n"
     ]
    }
   ],
   "source": [
    "!PYTHONPATH=src ./train.py --dataset /content/gpt-2/peregrine.txt --model_name '345M'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vS1RJJDFOPnb"
   },
   "source": [
    "Save our checkpoints to start training again later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JretqG1zOXdi"
   },
   "outputs": [],
   "source": [
    "!cp -r /content/gpt-2/checkpoint/ /content/drive/My\\ Drive/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6D-i7vERWbNS"
   },
   "source": [
    "Load your trained model for use in sampling below (117M or 345M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VeETvWvrbKga"
   },
   "outputs": [],
   "source": [
    "!cp -r /content/gpt-2/checkpoint/run1/* /content/gpt-2/models/117M/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "np0r6qfXBeUX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: directory /content/gpt-2/models/345M does not exist\n"
     ]
    }
   ],
   "source": [
    "!cp -r /content/gpt-2/checkpoint/run1/* /content/gpt-2/models/345M/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GmnSrXqtfRbq"
   },
   "source": [
    "Generate conditional samples from the model given a prompt you provide -  change top-k hyperparameter if desired (default is 40),  if you're using 345M, add \"--model-name 345M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "utJj-iY4gHwE"
   },
   "outputs": [],
   "source": [
    "!python3 src/interactive_conditional_samples.py --top_k 40 --model_name \"345M\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LeDhY97XMDXn"
   },
   "source": [
    "To check flag descriptions, use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pBaj2L_KMAgb"
   },
   "outputs": [],
   "source": [
    "!python3 src/interactive_conditional_samples.py -- --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K8rSqkGxg5OK"
   },
   "source": [
    "Generate unconditional samples from the model,  if you're using 345M, add \"--model-name 345M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LaQUEnRxWc3c"
   },
   "outputs": [],
   "source": [
    "!python3 src/generate_unconditional_samples.py --model_name \"345M\" | tee /tmp/samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VM1Hag-JL3Bt"
   },
   "source": [
    "To check flag descriptions, use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sdxfye-SL66I"
   },
   "outputs": [],
   "source": [
    "!python3 src/generate_unconditional_samples.py -- --help"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of GPT-2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
