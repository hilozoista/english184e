{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Mimicking The Peregrine</h1>\n",
    "Didi Chang-Park\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import pyvis\n",
    "from pyvis.network import Network\n",
    "lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "text_folder = '../corpora/peregrine/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.append('is')\n",
    "stop_words.remove('as')\n",
    "stop_words.append('a')\n",
    "parts = ['N','V','A','D','P']\n",
    "colordict = {}\n",
    "colordict['N'] = ['green',15]\n",
    "colordict['V'] = ['red',15]\n",
    "colordict['A'] = ['pink',15]\n",
    "colordict['D'] = ['#c0c1c4',15]\n",
    "colordict['P'] = ['yellow',15]\n",
    "birds = ('falcon',\"peregrine\",\"tiercel\",\"lapwing\",\"woodcock\",\"curlew\",\"heron\",\"sandpiper\",\n",
    "        \"snipe\",\"wigeon\",\"starling\",\"skylark\",\"gull\",\"owl\",\"mallard\",\"woodpigeons\",\"swan\",\n",
    "        \"jackdaw\",\"lark\",\"plover\",\"partridge\",\"pigeon\",\"duck\",\"hawk\",\"crow\",\"teal\",\"wildfowl\",\n",
    "        \"blackbird\",\"bunting\",\"swallow\",\"martin\",\"kestrel\",\"jay\",\"plover\",\"sanderling\",\n",
    "        \"wader\",\"pheasant\",\"greenshank\",\"grebe\",\"pied\",\"wagtail\",\"moorhen\",\"thrush\",\"finch\")\n",
    "for bird in birds:\n",
    "    colordict[bird] = [\"blue\",40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes word frequency dictionary for entire corpus\n",
    "with open(text_folder+\"/hidden/the-hunting-life.txt\") as file:\n",
    "    filetext = file.read().lower().split()\n",
    "with open(text_folder+\"hidden/markov-life.txt\",\"w\") as file:\n",
    "    for fn in os.listdir(text_folder):\n",
    "        if(fn[0]==\"_\"):\n",
    "            file.write(open(text_folder+fn).read()+\"\\n\")\n",
    "markovtext = open(text_folder+\"hidden/markov-life.txt\",\"r\").read().lower().split()\n",
    "new = filetext+markovtext\n",
    "words = []\n",
    "for word in new:\n",
    "    if(word==\"as\"):\n",
    "        words.append(word)\n",
    "    if(word==\"was\"):\n",
    "        words.append(word)\n",
    "    else:\n",
    "        words.append(lemma.lemmatize(re.sub(r'[^\\w\\-\\s]', '', word)))\n",
    "freqdist={}\n",
    "for word in words:\n",
    "    if word not in freqdist.keys():\n",
    "        freqdist[word]=1\n",
    "    else:\n",
    "        freqdist[word]+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> HELPER METHODS </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getsents(text):\n",
    "    #with open(text_folder+fn) as file:\n",
    "    #    filetext = file.read().lower()\n",
    "    sents_unstripped = nltk.sent_tokenize(text.lower())\n",
    "    sents_unstopped = []\n",
    "    for s in sents_unstripped:\n",
    "        sents_unstopped.append(re.sub(r'[^\\w\\-\\s]', '',s).split())\n",
    "    sents = []\n",
    "    for s in sents_unstopped:\n",
    "        st = []\n",
    "        for w in s:\n",
    "            if w not in stop_words:\n",
    "                if(w==\"as\"):\n",
    "                    st.append(\"as\")\n",
    "                if(w==\"was\"):\n",
    "                    st.append(\"was\")\n",
    "                else:\n",
    "                    st.append(lemma.lemmatize(w))\n",
    "        sents.append(st)\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParts(sents):\n",
    "    sent_holder = []    \n",
    "    part_dict = {}\n",
    "    for s in sents:\n",
    "        tags = nltk.pos_tag(s)\n",
    "        sholder = []\n",
    "        for tag in tags:\n",
    "            if(tag[1][:1] in parts):\n",
    "                sholder.append(tag[0])\n",
    "            part_dict[tag[0]] = tag[1]\n",
    "        if(len(sholder)!=0):\n",
    "            sent_holder.append(sholder)\n",
    "    return part_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thanks to ryan for this method, which I've slightly modified\n",
    "def draw_graph3(networkx_graph,notebook=True,output_filename='graph.html',show_buttons=False,only_physics_buttons=False):\n",
    "    # import\n",
    "    from pyvis import network as net\n",
    "    \n",
    "    # make a pyvis network\n",
    "    pyvis_graph = net.Network(notebook=notebook, height=\"750px\", width=\"100%\")\n",
    "    \n",
    "    # for each node and its attributes in the networkx graph\n",
    "    for node,node_attrs in networkx_graph.nodes(data=True):\n",
    "        pyvis_graph.add_node(node,**node_attrs)\n",
    "        \n",
    "    # for each edge and its attributes in the networkx graph\n",
    "    for source,target,edge_attrs in networkx_graph.edges(data=True):\n",
    "        # if value/width not specified directly, and weight is specified, set 'value' to 'weight'\n",
    "        if not 'value' in edge_attrs and not 'width' in edge_attrs and 'weight' in edge_attrs:\n",
    "            # place at key 'value' the weight of the edge\n",
    "            edge_attrs['value']=edge_attrs['weight']\n",
    "        # add the edge\n",
    "        pyvis_graph.add_edge(source,target,**edge_attrs)\n",
    "\n",
    "    pyvis_graph.set_edge_smooth('dynamic')\n",
    "    # return and also save\n",
    "    return pyvis_graph.show(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makegraph(sents):\n",
    "    G = nx.Graph()\n",
    "    part_dict = getParts(sents)\n",
    "    \n",
    "    num_sents = len(sents)\n",
    "    storelast = \"\"\n",
    "    for s in sents:\n",
    "        bigs = list(nltk.bigrams(s))\n",
    "        if(len(bigs)>0):\n",
    "            if sents.index(s)>0:\n",
    "                G.add_edge(storelast, bigs[0][0])\n",
    "            for pair in bigs:\n",
    "                p0 = part_dict[pair[0]][:1]\n",
    "                p1 = part_dict[pair[1]][:1]\n",
    "                size0 = 1/freqdist[pair[0]]*30+10\n",
    "                size1 = 1/freqdist[pair[1]]*30+10\n",
    "                attribs=['#8c8c8c','#8c8c8c',7,7]\n",
    "                if(p0 in colordict):\n",
    "                    attribs[0]=colordict[p0][0]\n",
    "                if(p1 in colordict):\n",
    "                    attribs[1]=colordict[p1][0]\n",
    "                if(pair[0] in birds):\n",
    "                    attribs[0] = \"blue\"\n",
    "                    size0+=30\n",
    "                if(pair[1] in birds):\n",
    "                    attribs[1] = \"blue\"\n",
    "                    size1+=30\n",
    "                G.add_node(pair[0],color=attribs[0], size=size0)\n",
    "                G.add_node(pair[1],color=attribs[1], size=size1)\n",
    "                if(\"peregrine\" in s):\n",
    "                    edgec = \"blue\"\n",
    "                else:\n",
    "                    edgec = \"red\"\n",
    "                G.add_edge(pair[0], pair[1],color=edgec)\n",
    "            if sents.index(s)<num_sents-1:\n",
    "                storelast = bigs[len(bigs)-1][1]\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> MARKOV SECTION </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify\n",
    "import numpy\n",
    "import natsort\n",
    "import matplotlib.pyplot as plt\n",
    "text_folder = '../corpora/peregrine/'\n",
    "\n",
    "seasons = {\n",
    "    \"oct\" : \"fall\",\n",
    "    \"nov\" : \"fall\",\n",
    "    \"dec\" : \"winter\",\n",
    "    \"jan\" : \"winter\",\n",
    "    \"feb\" : \"winter\",\n",
    "    \"mar\" : \"spring\",\n",
    "    \"apr\" : \"spring\"\n",
    "}\n",
    "ss = 3 #state size   \n",
    "\n",
    "with open(text_folder+\"/hidden/the-hunting-life.txt\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "seasons_texts = {}\n",
    "for season in seasons.values():\n",
    "    with open(text_folder+\"/hidden/seasons/\"+season+\".txt\") as f:\n",
    "        text = f.read()\n",
    "        seasons_texts[season] = text\n",
    "    \n",
    "with open(text_folder+\"/hidden/first-lines.txt\") as f:\n",
    "    text = f.read()\n",
    "    firstline_model = markovify.Text(text, state_size=ss)\n",
    "    \n",
    "def markovify(fn):\n",
    "    import markovify\n",
    "    whole_model = markovify.Text(text, state_size=ss)\n",
    "    with open(text_folder+fn) as f:\n",
    "        txt = f.read()\n",
    "        txt_model = markovify.Text(txt, state_size=ss)\n",
    "    season_model = markovify.Text(seasons_texts[seasons[fn[3:6]]], state_size=ss)\n",
    "    full_model = markovify.combine([whole_model, season_model,txt_model], [1,2,2.5])\n",
    "    first_model = markovify.combine([firstline_model,season_model],[2,1])\n",
    "    new_text=\"\"\n",
    "    sd = sent_data(fn)\n",
    "    num_sents = sd[1][6]\n",
    "    max_len = sd[1][0]\n",
    "    wc = sd[1][4]\n",
    "    curlen = 0\n",
    "    while True:\n",
    "        new = first_model.make_sentence()\n",
    "        if(new!=None):\n",
    "            new_text+=(new+\" \")\n",
    "            curlen+=(new.count(\" \")+1)\n",
    "            break\n",
    "    else:\n",
    "        new = first_model.make_sentence()\n",
    "    i=1\n",
    "    while i<num_sents:\n",
    "        new = full_model.make_sentence()\n",
    "        if(new!=None):\n",
    "            new_text+=(new+\" \")\n",
    "            curlen+=new.count(\" \")+1\n",
    "            i+=1\n",
    "    m = open(text_folder+\"_\"+fn, \"w+\")\n",
    "    m.write(new_text)\n",
    "    m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> SENTENCE SECTION </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_data(filename):\n",
    "    import numpy\n",
    "    sent_len = []\n",
    "    with open(text_folder+filename) as f:\n",
    "        text = f.read().strip(\"\\n\").split(\".\")\n",
    "        text[0]+=\" \"\n",
    "        rare=set()\n",
    "        for sent in text:\n",
    "            if(sent!=\" \" and sent!=\"\"):\n",
    "                sentlen = sent.count(\" \")\n",
    "                sent_len.append(sentlen)\n",
    "            #ADD WORDS WHICH APPEAR 3 OR FEWER TIMES TO SET\n",
    "            #TO COUNT NUMBER OF UNIQUE RARE WORDS IN FILE\n",
    "            for w in sent.split(\" \"): \n",
    "                if(w in freqdist.keys()):\n",
    "                    if(freqdist[w]<4):\n",
    "                        rare.add(w)\n",
    "                        print(w)\n",
    "        \n",
    "        #max sent length, min sent length, mean sent length, standard deviation on sent length,  number of words, number of unique rare words, num sentences\n",
    "        data = [max(sent_len), min(sent_len),sum(sent_len)/len(sent_len), numpy.std(sent_len), sum(sent_len),len(rare), len(sent_len)]\n",
    "    return([sent_len,data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates the CSV metadata\n",
    "dr=os.listdir(text_folder)\n",
    "nr = natsort.natsorted(dr)\n",
    "with open(text_folder+\"peregrine.csv\", \"w+\") as file:\n",
    "    file.write(\"fn,season,author\\n\")\n",
    "    for fn in nr:\n",
    "        author=\"baker\"\n",
    "        month=fn[3:6]\n",
    "        if(fn[-3:]==\"txt\"):\n",
    "            if(fn[0]==\"_\"):\n",
    "                author=\"markov\"\n",
    "                month = fn[4:7]\n",
    "            elif(fn[0]==\"-\"):\n",
    "                author=\"gpt-2\"\n",
    "                month = fn[4:7]\n",
    "            file.write(fn+\",\"+seasons[month]+\",\"+author+\"\\n\")\n",
    "    file.close()\n",
    "\n",
    "# Get the metadata for this corpus\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dtm(text_folder,normalize=False):\n",
    "\n",
    "    # make an empty results list\n",
    "    all_results = []\n",
    "    \n",
    "    columns=[]\n",
    "    attrbs = ['max_sent_len','min_sent_len','mean_sent_len',\n",
    "             'sd_sent_len','num_words','rare_words_count']\n",
    "    columns.append('fn')\n",
    "    for att in attrbs:\n",
    "        columns.append(att)\n",
    "    \n",
    "    # for each filename\n",
    "    filenames=sorted(os.listdir(text_folder))\n",
    "    for fn in filenames:\n",
    "        if(fn[-3:]==\"txt\"):\n",
    "            text_result = {}\n",
    "            text_result[\"fn\"]=fn\n",
    "            #max sent length, min sent length, mean sent length, standard deviation on sent length, number of sents, number of words\n",
    "            text_result['max_sent_len']=sent_data(fn)[1][0]\n",
    "            text_result['min_sent_len']=sent_data(fn)[1][1]\n",
    "            text_result['mean_sent_len']=sent_data(fn)[1][2]\n",
    "            text_result['sd_sent_len']=sent_data(fn)[1][3]\n",
    "            text_result['num_words']=sent_data(fn)[1][4]\n",
    "            text_result['rare_words_count'] = sent_data(fn)[1][5]\n",
    "            all_results.append(text_result)         \n",
    "    \n",
    "    # Make dataframe\n",
    "    df = pd.DataFrame(all_results, columns=columns).set_index('fn').fillna(0)\n",
    "    \n",
    "    # return dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Markovifies all files </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in os.listdir(text_folder):\n",
    "    if(fn[0] not in [\"_\",\"-\"] and fn[-3:]==\"txt\"):\n",
    "        markovify(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Sentence Dataframe </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_metadata='../corpora/peregrine/peregrine.csv'\n",
    "df_meta = pd.read_csv(path_to_metadata).set_index('fn')\n",
    "dtm = make_dtm(text_folder,normalize=True)\n",
    "dtm_meta=df_meta.merge(dtm,on='fn')\n",
    "dtm_meta = dtm_meta[dtm_meta.author !=\"gpt-2\"]\n",
    "dtm_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_sent_len</th>\n",
       "      <th>min_sent_len</th>\n",
       "      <th>mean_sent_len</th>\n",
       "      <th>sd_sent_len</th>\n",
       "      <th>num_words</th>\n",
       "      <th>rare_words_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baker</th>\n",
       "      <td>36.080460</td>\n",
       "      <td>3.885057</td>\n",
       "      <td>15.250972</td>\n",
       "      <td>7.412125</td>\n",
       "      <td>591.367816</td>\n",
       "      <td>34.597701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>markov</th>\n",
       "      <td>32.126437</td>\n",
       "      <td>6.149425</td>\n",
       "      <td>16.970797</td>\n",
       "      <td>6.096420</td>\n",
       "      <td>662.287356</td>\n",
       "      <td>3.551724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        max_sent_len  min_sent_len  mean_sent_len  sd_sent_len   num_words  \\\n",
       "author                                                                       \n",
       "baker      36.080460      3.885057      15.250972     7.412125  591.367816   \n",
       "markov     32.126437      6.149425      16.970797     6.096420  662.287356   \n",
       "\n",
       "        rare_words_count  \n",
       "author                    \n",
       "baker          34.597701  \n",
       "markov          3.551724  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_meta.groupby('author').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sents(fn):\n",
    "    data = sent_data(fn)[0]\n",
    "    num_sents = sent_data(fn)[1][6]\n",
    "    plt.bar(range(1,num_sents+1),data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_sent_len, min_sent_len, mean_sent_len, sd_sent_len,num_words,rare_words_count,num_sents\n",
      "[34, 3, 15.555555555555555, 7.88967132270077, 280, 73, 18]\n",
      "[36, 8, 18.944444444444443, 8.017149827589895, 341, 77, 18]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_date = \"43_dec-18.txt\"\n",
    "markovify(test_date)\n",
    "print(\"max_sent_len, min_sent_len, mean_sent_len, sd_sent_len,num_words,rare_words_count,num_sents\")\n",
    "print(sent_data(test_date)[1])\n",
    "print(sent_data(\"_\"+test_date)[1])\n",
    "plot_sents(test_date)\n",
    "plot_sents(\"_\"+test_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> GRAPH SECTION </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_data(fn,verbose=True):\n",
    "    g = graph_dict[fn[:-4]]\n",
    "    d = dict(nx.degree(g))\n",
    "    max_degree = max(d.values())\n",
    "    hubs = sorted(zip(d.values(),d.keys()), reverse=True)[:3]\n",
    "    hubs_deg = hubs[0][0]+hubs[1][0]+hubs[2][0]\n",
    "    loss=g.number_of_edges()+1-dtm_meta.at[fn,\"num_words\"]\n",
    "    diameter = nx.diameter(g)\n",
    "    center = nx.center(g)\n",
    "    clustering = nx.average_clustering(g)\n",
    "    #closeness = nx.closeness_centrality(g).values()\n",
    "    dom_set = nx.dominating_set(g)\n",
    "    try:\n",
    "        max_ind = nx.maximal_independent_set(g)\n",
    "    except:\n",
    "        max_ind = {}\n",
    "    if(verbose):\n",
    "        print(\"hubs:\",hubs)\n",
    "        print(\"hubs_deg_sum:\", hubs_deg)\n",
    "        print(\"Loss:\",loss)\n",
    "        print(\"Diameter:\",diameter)\n",
    "        print(\"Center nodes:\",center)\n",
    "        print(\"Average clustering:\", clustering)\n",
    "        print(\"Dominating set:\",dom_set)\n",
    "        print(\"Dominating set length:\",len(dom_set))\n",
    "        print(\"Maximal independent set:\",max_ind)\n",
    "        print(\"Maximal independent set length:\",len(max_ind))\n",
    "    return([hubs, hubs_deg, loss, diameter,center,len(center),clustering,dom_set,len(dom_set),max_ind,len(max_ind)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Makes graphs for all files in directory </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../corpora/peregrine/'\n",
    "filenames = os.listdir(path)\n",
    "graph_dict = {}\n",
    "for f in filenames:\n",
    "    if(f[-3:] == \"txt\" and f[0]!=\"-\"):\n",
    "        filetext = open(path+f, \"r\").read()\n",
    "        graph_dict[f[:-4]]=makegraph(getsents(filetext))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Makes graphs for all files in directory </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph_dtm(text_folder,normalize=False):\n",
    "\n",
    "    # make an empty results list\n",
    "    all_results = []\n",
    "    \n",
    "    columns=[]\n",
    "\n",
    "    attrbs = ['hubs', 'hubs_deg_sum','loss','diameter',\n",
    "             'center', 'center_len','clustering','dom_set','len_dom_set','indep_set', 'len_indep_set']\n",
    "    columns.append('fn')\n",
    "    for att in attrbs:\n",
    "        columns.append(att)\n",
    "    \n",
    "    # for each filename\n",
    "    filenames=sorted(os.listdir(text_folder))\n",
    "    for fn in filenames:\n",
    "        if(fn[-3:]==\"txt\"):\n",
    "            text_result = {}\n",
    "            text_result[\"fn\"]=fn\n",
    "            gd = graph_data(fn, False)\n",
    "            \n",
    "            text_result['hubs']=gd[0]\n",
    "            text_result['hubs_deg_sum']=gd[1]\n",
    "            text_result['loss']=gd[2]\n",
    "            text_result['diameter']=gd[3]\n",
    "            text_result['center']=gd[4]\n",
    "            text_result['center_len'] = gd[5]\n",
    "            text_result['clustering']=gd[6]\n",
    "            text_result['dom_set']=gd[7]\n",
    "            text_result['len_dom_set']=gd[8]\n",
    "            text_result['indep_set']=gd[9]\n",
    "            text_result['len_indep_set']=gd[10]\n",
    "            all_results.append(text_result)\n",
    "            \n",
    "    \n",
    "    # Make dataframe\n",
    "    df = pd.DataFrame(all_results, columns=columns).set_index('fn').fillna(0)\n",
    "    \n",
    "    # return dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>author</th>\n",
       "      <th>hubs</th>\n",
       "      <th>hubs_deg_sum</th>\n",
       "      <th>loss</th>\n",
       "      <th>diameter</th>\n",
       "      <th>center</th>\n",
       "      <th>center_len</th>\n",
       "      <th>clustering</th>\n",
       "      <th>dom_set</th>\n",
       "      <th>len_dom_set</th>\n",
       "      <th>indep_set</th>\n",
       "      <th>len_indep_set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00_oct-1.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(12, sky), (12, jay), (12, hawk)]</td>\n",
       "      <td>36</td>\n",
       "      <td>-358</td>\n",
       "      <td>14</td>\n",
       "      <td>[sky, alder, river, hawk, water, watching, bli...</td>\n",
       "      <td>31</td>\n",
       "      <td>0.010929</td>\n",
       "      <td>{breast-bone, cloud, blurred, stumble, sleep, ...</td>\n",
       "      <td>160</td>\n",
       "      <td>[white-bannered, ate, terror, moving, ripple, ...</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_oct-3.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(12, wader), (11, beach), (10, sea)]</td>\n",
       "      <td>33</td>\n",
       "      <td>-112</td>\n",
       "      <td>14</td>\n",
       "      <td>[sun, sea, flashing, salting, wader, white, be...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{sky, fell, high, sleeping, white, billhook, r...</td>\n",
       "      <td>68</td>\n",
       "      <td>[whirling, shield, leg, shimmering, drifted, l...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02_oct-5.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(12, wing), (10, long), (9, hawk)]</td>\n",
       "      <td>31</td>\n",
       "      <td>-264</td>\n",
       "      <td>13</td>\n",
       "      <td>[orchard]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>{touching, cloud, high, tail, yet, rain-smoked...</td>\n",
       "      <td>116</td>\n",
       "      <td>[leg, distant, sometimes, grey-brown, veered, ...</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03_oct-7.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(14, wing), (8, peregrine), (6, tail)]</td>\n",
       "      <td>28</td>\n",
       "      <td>-320</td>\n",
       "      <td>18</td>\n",
       "      <td>[foot, two, hundred, passing, twice, as, a, gr...</td>\n",
       "      <td>21</td>\n",
       "      <td>0.016136</td>\n",
       "      <td>{proportion, slightly, looking, tail, rakish, ...</td>\n",
       "      <td>120</td>\n",
       "      <td>[slender, gull, life, stood, way, head, seen, ...</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04_oct-8.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(15, wader), (12, like), (9, inland)]</td>\n",
       "      <td>36</td>\n",
       "      <td>-169</td>\n",
       "      <td>15</td>\n",
       "      <td>[flew, like, wader, small, facing]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.020095</td>\n",
       "      <td>{high, dry, looking, saw, waterfall, horde, ri...</td>\n",
       "      <td>81</td>\n",
       "      <td>[horizon, turning, toy, stood, a, foot, snow, ...</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05_oct-9.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(8, sun), (8, like), (6, jay)]</td>\n",
       "      <td>22</td>\n",
       "      <td>-153</td>\n",
       "      <td>17</td>\n",
       "      <td>[hid, shining, martin, flew, hawk]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{bush, high, pike, late, looking, tail, saw, p...</td>\n",
       "      <td>78</td>\n",
       "      <td>[yellow, outwards, sang, swamp, like, flew, gl...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06_oct-12.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(22, hawk), (16, crow), (12, like)]</td>\n",
       "      <td>50</td>\n",
       "      <td>-349</td>\n",
       "      <td>15</td>\n",
       "      <td>[away, peregrine, come, inland, estuary, hawk,...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>{cloud, sleeping, high, grow, sleep, solitary,...</td>\n",
       "      <td>149</td>\n",
       "      <td>[swirl, come, prey, time, silent, sand-and-cla...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07_oct-14.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(14, water), (8, peregrine), (8, godwit)]</td>\n",
       "      <td>30</td>\n",
       "      <td>-76</td>\n",
       "      <td>20</td>\n",
       "      <td>[white, glinting, water, grey, plover, seldom,...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>{settling, cloud, calm, climbing, leaf, waggle...</td>\n",
       "      <td>77</td>\n",
       "      <td>[southern, knot, snuffling, faint, perching, f...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08_oct-15.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(10, peregrine), (10, flew), (10, falcon)]</td>\n",
       "      <td>30</td>\n",
       "      <td>-210</td>\n",
       "      <td>18</td>\n",
       "      <td>[peregrine, tiercel, falcon, quicker, plumage]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>{sparrow, high, slightly, tail, involved, skyl...</td>\n",
       "      <td>97</td>\n",
       "      <td>[back, gain, falcon, baggy, plumage, within, f...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09_oct-16.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(10, spray), (8, water), (8, sky)]</td>\n",
       "      <td>26</td>\n",
       "      <td>-181</td>\n",
       "      <td>17</td>\n",
       "      <td>[spray, leapt, wave, along, shingle, ridge, fa...</td>\n",
       "      <td>18</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>{fire, high, dry, saw, pale, ridge, northern, ...</td>\n",
       "      <td>84</td>\n",
       "      <td>[flicking, straight, sea-wall, short, shore, a...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_77_mar-23.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(30, flew), (17, wing), (17, sun)]</td>\n",
       "      <td>64</td>\n",
       "      <td>-964</td>\n",
       "      <td>12</td>\n",
       "      <td>[killed, low, gusty, air, sky, still, hawk, be...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.007703</td>\n",
       "      <td>{breathe, thundered, cloud, late, copper, moti...</td>\n",
       "      <td>202</td>\n",
       "      <td>[bank, solid, soared, renewing, gusty, flutter...</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_78_mar-25.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(14, flew), (13, wing), (11, tree)]</td>\n",
       "      <td>38</td>\n",
       "      <td>-542</td>\n",
       "      <td>15</td>\n",
       "      <td>[sun, curved, back, flew, orchard, towards]</td>\n",
       "      <td>6</td>\n",
       "      <td>0.017281</td>\n",
       "      <td>{motion, irritating, starkness, choose, increa...</td>\n",
       "      <td>161</td>\n",
       "      <td>[hovered, flew, sweeping, stabbed, tiercel, ra...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_79_mar-27.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(20, flew), (15, sun), (14, hawk)]</td>\n",
       "      <td>49</td>\n",
       "      <td>-626</td>\n",
       "      <td>16</td>\n",
       "      <td>[hawk, wind, flew, began, sky, south, skin]</td>\n",
       "      <td>7</td>\n",
       "      <td>0.021666</td>\n",
       "      <td>{withdrawn, breathe, cloud, say, sleeping, tor...</td>\n",
       "      <td>178</td>\n",
       "      <td>[figure, hovering, called, interest, softened,...</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_80_mar-28.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(37, flew), (16, wind), (15, estuary)]</td>\n",
       "      <td>68</td>\n",
       "      <td>-941</td>\n",
       "      <td>10</td>\n",
       "      <td>[flew, estuary, cold, suddenly, across, grass,...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.026680</td>\n",
       "      <td>{thundered, cloud, late, sawdust, rim, grow, s...</td>\n",
       "      <td>201</td>\n",
       "      <td>[winding, downwards, bird, went, flooded, thin...</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_81_mar-29.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(16, sky), (16, flew), (14, owl)]</td>\n",
       "      <td>46</td>\n",
       "      <td>-585</td>\n",
       "      <td>15</td>\n",
       "      <td>[sun, north]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.015461</td>\n",
       "      <td>{fuss, cloud, say, sawdust, torrent, grow, kes...</td>\n",
       "      <td>163</td>\n",
       "      <td>[took, slow, brown, seen, gleamed, perching, b...</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_82_mar-30.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(12, tree), (6, saw), (6, grass)]</td>\n",
       "      <td>24</td>\n",
       "      <td>-130</td>\n",
       "      <td>26</td>\n",
       "      <td>[as, a, rising]</td>\n",
       "      <td>3</td>\n",
       "      <td>0.015320</td>\n",
       "      <td>{cleaving, sky, white, pierced, landed, grow, ...</td>\n",
       "      <td>58</td>\n",
       "      <td>[cleaving, spring, land, tree-fringed, tiercel...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_83_mar-31.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(13, flew), (12, tree), (10, long)]</td>\n",
       "      <td>35</td>\n",
       "      <td>-394</td>\n",
       "      <td>16</td>\n",
       "      <td>[long, estuary, together]</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>{cloud, torrent, carrying, migrant, southern, ...</td>\n",
       "      <td>110</td>\n",
       "      <td>[sea-sky, top, winter, upward, lifted, brimmed...</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_84_apr-2.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(12, wind), (12, away), (10, sky)]</td>\n",
       "      <td>34</td>\n",
       "      <td>-324</td>\n",
       "      <td>14</td>\n",
       "      <td>[away]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007278</td>\n",
       "      <td>{fire, thundered, say, late, high, cloud, star...</td>\n",
       "      <td>101</td>\n",
       "      <td>[sail, lower, tree, neck, saw, hand, sea-sky, ...</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_85_apr-3.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(21, flew), (16, sun), (14, hawk)]</td>\n",
       "      <td>51</td>\n",
       "      <td>-545</td>\n",
       "      <td>13</td>\n",
       "      <td>[flew, sun, hovered]</td>\n",
       "      <td>3</td>\n",
       "      <td>0.024469</td>\n",
       "      <td>{cloud, motion, late, moment, scolded, increas...</td>\n",
       "      <td>163</td>\n",
       "      <td>[perch, much, slid, drifting, brimmed, mile, h...</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_86_apr-4.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(14, sun), (14, sky), (13, wing)]</td>\n",
       "      <td>41</td>\n",
       "      <td>-708</td>\n",
       "      <td>11</td>\n",
       "      <td>[called, flew, sky, shone, as, a, side, clear,...</td>\n",
       "      <td>56</td>\n",
       "      <td>0.022068</td>\n",
       "      <td>{breathe, cloud, say, sawdust, starkness, grow...</td>\n",
       "      <td>161</td>\n",
       "      <td>[sky, haze, wheatear, sun, pause, snow, though...</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                season  author                                         hubs  \\\n",
       "fn                                                                            \n",
       "00_oct-1.txt      fall   baker           [(12, sky), (12, jay), (12, hawk)]   \n",
       "01_oct-3.txt      fall   baker        [(12, wader), (11, beach), (10, sea)]   \n",
       "02_oct-5.txt      fall   baker          [(12, wing), (10, long), (9, hawk)]   \n",
       "03_oct-7.txt      fall   baker      [(14, wing), (8, peregrine), (6, tail)]   \n",
       "04_oct-8.txt      fall   baker       [(15, wader), (12, like), (9, inland)]   \n",
       "05_oct-9.txt      fall   baker              [(8, sun), (8, like), (6, jay)]   \n",
       "06_oct-12.txt     fall   baker         [(22, hawk), (16, crow), (12, like)]   \n",
       "07_oct-14.txt     fall   baker   [(14, water), (8, peregrine), (8, godwit)]   \n",
       "08_oct-15.txt     fall   baker  [(10, peregrine), (10, flew), (10, falcon)]   \n",
       "09_oct-16.txt     fall   baker          [(10, spray), (8, water), (8, sky)]   \n",
       "...                ...     ...                                          ...   \n",
       "_77_mar-23.txt  spring  markov          [(30, flew), (17, wing), (17, sun)]   \n",
       "_78_mar-25.txt  spring  markov         [(14, flew), (13, wing), (11, tree)]   \n",
       "_79_mar-27.txt  spring  markov          [(20, flew), (15, sun), (14, hawk)]   \n",
       "_80_mar-28.txt  spring  markov      [(37, flew), (16, wind), (15, estuary)]   \n",
       "_81_mar-29.txt  spring  markov           [(16, sky), (16, flew), (14, owl)]   \n",
       "_82_mar-30.txt  spring  markov           [(12, tree), (6, saw), (6, grass)]   \n",
       "_83_mar-31.txt  spring  markov         [(13, flew), (12, tree), (10, long)]   \n",
       "_84_apr-2.txt   spring  markov          [(12, wind), (12, away), (10, sky)]   \n",
       "_85_apr-3.txt   spring  markov          [(21, flew), (16, sun), (14, hawk)]   \n",
       "_86_apr-4.txt   spring  markov           [(14, sun), (14, sky), (13, wing)]   \n",
       "\n",
       "                hubs_deg_sum  loss  diameter  \\\n",
       "fn                                             \n",
       "00_oct-1.txt              36  -358        14   \n",
       "01_oct-3.txt              33  -112        14   \n",
       "02_oct-5.txt              31  -264        13   \n",
       "03_oct-7.txt              28  -320        18   \n",
       "04_oct-8.txt              36  -169        15   \n",
       "05_oct-9.txt              22  -153        17   \n",
       "06_oct-12.txt             50  -349        15   \n",
       "07_oct-14.txt             30   -76        20   \n",
       "08_oct-15.txt             30  -210        18   \n",
       "09_oct-16.txt             26  -181        17   \n",
       "...                      ...   ...       ...   \n",
       "_77_mar-23.txt            64  -964        12   \n",
       "_78_mar-25.txt            38  -542        15   \n",
       "_79_mar-27.txt            49  -626        16   \n",
       "_80_mar-28.txt            68  -941        10   \n",
       "_81_mar-29.txt            46  -585        15   \n",
       "_82_mar-30.txt            24  -130        26   \n",
       "_83_mar-31.txt            35  -394        16   \n",
       "_84_apr-2.txt             34  -324        14   \n",
       "_85_apr-3.txt             51  -545        13   \n",
       "_86_apr-4.txt             41  -708        11   \n",
       "\n",
       "                                                           center  center_len  \\\n",
       "fn                                                                              \n",
       "00_oct-1.txt    [sky, alder, river, hawk, water, watching, bli...          31   \n",
       "01_oct-3.txt    [sun, sea, flashing, salting, wader, white, be...          26   \n",
       "02_oct-5.txt                                            [orchard]           1   \n",
       "03_oct-7.txt    [foot, two, hundred, passing, twice, as, a, gr...          21   \n",
       "04_oct-8.txt                   [flew, like, wader, small, facing]           5   \n",
       "05_oct-9.txt                   [hid, shining, martin, flew, hawk]           5   \n",
       "06_oct-12.txt   [away, peregrine, come, inland, estuary, hawk,...          16   \n",
       "07_oct-14.txt   [white, glinting, water, grey, plover, seldom,...          11   \n",
       "08_oct-15.txt      [peregrine, tiercel, falcon, quicker, plumage]           5   \n",
       "09_oct-16.txt   [spray, leapt, wave, along, shingle, ridge, fa...          18   \n",
       "...                                                           ...         ...   \n",
       "_77_mar-23.txt  [killed, low, gusty, air, sky, still, hawk, be...          23   \n",
       "_78_mar-25.txt        [sun, curved, back, flew, orchard, towards]           6   \n",
       "_79_mar-27.txt        [hawk, wind, flew, began, sky, south, skin]           7   \n",
       "_80_mar-28.txt  [flew, estuary, cold, suddenly, across, grass,...          23   \n",
       "_81_mar-29.txt                                       [sun, north]           2   \n",
       "_82_mar-30.txt                                    [as, a, rising]           3   \n",
       "_83_mar-31.txt                          [long, estuary, together]           3   \n",
       "_84_apr-2.txt                                              [away]           1   \n",
       "_85_apr-3.txt                                [flew, sun, hovered]           3   \n",
       "_86_apr-4.txt   [called, flew, sky, shone, as, a, side, clear,...          56   \n",
       "\n",
       "                clustering                                            dom_set  \\\n",
       "fn                                                                              \n",
       "00_oct-1.txt      0.010929  {breast-bone, cloud, blurred, stumble, sleep, ...   \n",
       "01_oct-3.txt      0.000000  {sky, fell, high, sleeping, white, billhook, r...   \n",
       "02_oct-5.txt      0.004715  {touching, cloud, high, tail, yet, rain-smoked...   \n",
       "03_oct-7.txt      0.016136  {proportion, slightly, looking, tail, rakish, ...   \n",
       "04_oct-8.txt      0.020095  {high, dry, looking, saw, waterfall, horde, ri...   \n",
       "05_oct-9.txt      0.000000  {bush, high, pike, late, looking, tail, saw, p...   \n",
       "06_oct-12.txt     0.005779  {cloud, sleeping, high, grow, sleep, solitary,...   \n",
       "07_oct-14.txt     0.007088  {settling, cloud, calm, climbing, leaf, waggle...   \n",
       "08_oct-15.txt     0.008955  {sparrow, high, slightly, tail, involved, skyl...   \n",
       "09_oct-16.txt     0.002646  {fire, high, dry, saw, pale, ridge, northern, ...   \n",
       "...                    ...                                                ...   \n",
       "_77_mar-23.txt    0.007703  {breathe, thundered, cloud, late, copper, moti...   \n",
       "_78_mar-25.txt    0.017281  {motion, irritating, starkness, choose, increa...   \n",
       "_79_mar-27.txt    0.021666  {withdrawn, breathe, cloud, say, sleeping, tor...   \n",
       "_80_mar-28.txt    0.026680  {thundered, cloud, late, sawdust, rim, grow, s...   \n",
       "_81_mar-29.txt    0.015461  {fuss, cloud, say, sawdust, torrent, grow, kes...   \n",
       "_82_mar-30.txt    0.015320  {cleaving, sky, white, pierced, landed, grow, ...   \n",
       "_83_mar-31.txt    0.007015  {cloud, torrent, carrying, migrant, southern, ...   \n",
       "_84_apr-2.txt     0.007278  {fire, thundered, say, late, high, cloud, star...   \n",
       "_85_apr-3.txt     0.024469  {cloud, motion, late, moment, scolded, increas...   \n",
       "_86_apr-4.txt     0.022068  {breathe, cloud, say, sawdust, starkness, grow...   \n",
       "\n",
       "                len_dom_set  \\\n",
       "fn                            \n",
       "00_oct-1.txt            160   \n",
       "01_oct-3.txt             68   \n",
       "02_oct-5.txt            116   \n",
       "03_oct-7.txt            120   \n",
       "04_oct-8.txt             81   \n",
       "05_oct-9.txt             78   \n",
       "06_oct-12.txt           149   \n",
       "07_oct-14.txt            77   \n",
       "08_oct-15.txt            97   \n",
       "09_oct-16.txt            84   \n",
       "...                     ...   \n",
       "_77_mar-23.txt          202   \n",
       "_78_mar-25.txt          161   \n",
       "_79_mar-27.txt          178   \n",
       "_80_mar-28.txt          201   \n",
       "_81_mar-29.txt          163   \n",
       "_82_mar-30.txt           58   \n",
       "_83_mar-31.txt          110   \n",
       "_84_apr-2.txt           101   \n",
       "_85_apr-3.txt           163   \n",
       "_86_apr-4.txt           161   \n",
       "\n",
       "                                                        indep_set  \\\n",
       "fn                                                                  \n",
       "00_oct-1.txt    [white-bannered, ate, terror, moving, ripple, ...   \n",
       "01_oct-3.txt    [whirling, shield, leg, shimmering, drifted, l...   \n",
       "02_oct-5.txt    [leg, distant, sometimes, grey-brown, veered, ...   \n",
       "03_oct-7.txt    [slender, gull, life, stood, way, head, seen, ...   \n",
       "04_oct-8.txt    [horizon, turning, toy, stood, a, foot, snow, ...   \n",
       "05_oct-9.txt    [yellow, outwards, sang, swamp, like, flew, gl...   \n",
       "06_oct-12.txt   [swirl, come, prey, time, silent, sand-and-cla...   \n",
       "07_oct-14.txt   [southern, knot, snuffling, faint, perching, f...   \n",
       "08_oct-15.txt   [back, gain, falcon, baggy, plumage, within, f...   \n",
       "09_oct-16.txt   [flicking, straight, sea-wall, short, shore, a...   \n",
       "...                                                           ...   \n",
       "_77_mar-23.txt  [bank, solid, soared, renewing, gusty, flutter...   \n",
       "_78_mar-25.txt  [hovered, flew, sweeping, stabbed, tiercel, ra...   \n",
       "_79_mar-27.txt  [figure, hovering, called, interest, softened,...   \n",
       "_80_mar-28.txt  [winding, downwards, bird, went, flooded, thin...   \n",
       "_81_mar-29.txt  [took, slow, brown, seen, gleamed, perching, b...   \n",
       "_82_mar-30.txt  [cleaving, spring, land, tree-fringed, tiercel...   \n",
       "_83_mar-31.txt  [sea-sky, top, winter, upward, lifted, brimmed...   \n",
       "_84_apr-2.txt   [sail, lower, tree, neck, saw, hand, sea-sky, ...   \n",
       "_85_apr-3.txt   [perch, much, slid, drifting, brimmed, mile, h...   \n",
       "_86_apr-4.txt   [sky, haze, wheatear, sun, pause, snow, though...   \n",
       "\n",
       "                len_indep_set  \n",
       "fn                             \n",
       "00_oct-1.txt              151  \n",
       "01_oct-3.txt               73  \n",
       "02_oct-5.txt              117  \n",
       "03_oct-7.txt              114  \n",
       "04_oct-8.txt               80  \n",
       "05_oct-9.txt               75  \n",
       "06_oct-12.txt             140  \n",
       "07_oct-14.txt              75  \n",
       "08_oct-15.txt              91  \n",
       "09_oct-16.txt              86  \n",
       "...                       ...  \n",
       "_77_mar-23.txt            198  \n",
       "_78_mar-25.txt            155  \n",
       "_79_mar-27.txt            182  \n",
       "_80_mar-28.txt            210  \n",
       "_81_mar-29.txt            159  \n",
       "_82_mar-30.txt             55  \n",
       "_83_mar-31.txt            113  \n",
       "_84_apr-2.txt             104  \n",
       "_85_apr-3.txt             149  \n",
       "_86_apr-4.txt             163  \n",
       "\n",
       "[174 rows x 13 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdtm = make_graph_dtm(text_folder,normalize=True)\n",
    "gdtm_meta=df_meta.merge(gdtm,on='fn')\n",
    "#gdtm_meta = gdtm_meta[dtm_meta.author !=\"gpt-2\"]\n",
    "gdtm_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hubs_deg_sum</th>\n",
       "      <th>loss</th>\n",
       "      <th>diameter</th>\n",
       "      <th>center_len</th>\n",
       "      <th>clustering</th>\n",
       "      <th>len_dom_set</th>\n",
       "      <th>len_indep_set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baker</th>\n",
       "      <td>33.275862</td>\n",
       "      <td>-269.804598</td>\n",
       "      <td>17.701149</td>\n",
       "      <td>6.988506</td>\n",
       "      <td>0.011279</td>\n",
       "      <td>109.218391</td>\n",
       "      <td>107.816092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>markov</th>\n",
       "      <td>32.390805</td>\n",
       "      <td>-341.057471</td>\n",
       "      <td>15.965517</td>\n",
       "      <td>6.908046</td>\n",
       "      <td>0.012220</td>\n",
       "      <td>104.195402</td>\n",
       "      <td>103.816092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        hubs_deg_sum        loss   diameter  center_len  clustering  \\\n",
       "author                                                                \n",
       "baker      33.275862 -269.804598  17.701149    6.988506    0.011279   \n",
       "markov     32.390805 -341.057471  15.965517    6.908046    0.012220   \n",
       "\n",
       "        len_dom_set  len_indep_set  \n",
       "author                              \n",
       "baker    109.218391     107.816092  \n",
       "markov   104.195402     103.816092  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdtm_meta.groupby('author').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hubs: [(21, 'flew'), (16, 'sun'), (14, 'hawk')]\n",
      "hubs_deg_sum: 51\n",
      "Loss: -545\n",
      "Diameter: 13\n",
      "Center nodes: ['flew', 'sun', 'hovered']\n",
      "Average clustering: 0.02446897446897447\n",
      "Dominating set: {'cloud', 'motion', 'late', 'moment', 'scolded', 'increasing', 'northern', 'yet', 'reached', 'going', 'tarnished', 'leaf', 'leap', 'clear', 'dreariness', 'swoop', 'ten', 'mouth', 'till', 'life', 'later', 'dead', 'featureless', 'unhappy-looking', 'using', 'air', 'float', 'masthead', 'tilted', 'coppice', 'blood', 'simply', 'startled', 'creek', 'wait', 'pond', 'west', 'three', 'marsh', 'estuary', 'bulk', 'hill', 'briefly', 'distorted', 'frequently', 'plover', 'perching', 'crackling', 'beating', 'plunged', 'filled', 'edge', 'feathering', 'river', 'dived', 'woodpigeons', 'watching', 'found', 'flash', 'rested', 'long', 'land', 'moved', 'flashed', 'eroded', 'every', 'place', 'gathering', 'cutting', 'two', 'stooped', 'changed', 'shifting', 'head', 'tide', 'half', 'apple', 'near', 'foot', 'diving', 'slid', 'sleekly', 'shone', 'stayed', 'ended', 'magpie', 'lifted', 'yard', 'wall', 'ignored', 'prey', 'dying', 'ploughland', 'predatory', 'staring', 'hunting', 'truly', 'blur', 'strong', 'landed', 'sight', 'folded', 'diamond', 'island', 'looked', 'south-east', 'wild', 'hollow', 'sank', 'wych', 'sea', 'though', 'fieldfare', 'tiercel', 'small', 'spiralled', 'amber', 'redshank', 'shore', 'sharp', 'followed', 'suddenly', 'hoping', 'jaw', 'cut', 'fly', 'wood', 'became', 'thin', 'old', 'monotonous', 'come', 'breast', 'broken', 'hedge', 'knew', 'shed', 'le', 'rainy', 'speed', 'calling', 'woodpigeon', 'could', 'sears', 'large', 'watched', 'curved', 'top', 'marshy', 'rippled', 'graceful', 'overhead', 'evening', 'owl', 'passed', 'renewing', 'thirty', 'south', 'rose', 'resting', 'arise', 'mile', 'snipe'}\n",
      "Dominating set length: 163\n",
      "Maximal independent set: ['pond', 'amber', 'field', 'completely', 'sight', 'watched', 'along', 'apple', 'exhausted', 'as', 'wych', 'half', 'rippled', 'cold', 'long', 'tumbling', 'twenty', 'brimmed', 'edge', 'barn', 'wind', 'northern', 'marshy', 'knew', 'poised', 'place', 'moment', 'small', 'speck', 'peering', 'saw', 'folded', 'using', 'brook', 'feathering', 'monotonous', 'distorted', 'hovering', 'breast', 'till', 'one', 'shifting', 'crackling', 'searing', 'moved', 'going', 'image', 'cart', 'jackdaw', 'went', 'marsh', 'increasing', 'sears', 'slid', 'dreariness', 'side', 'five', 'prey', 'le', 'bridge', 'gull', 'sinking', 'plunged', 'accept', 'leaf', 'coppice', 'cut', 'hoping', 'hollow', 'truly', 'surface', 'drifting', 'unhappy-looking', 'come', 'slack', 'alder', 'south-east', 'jaw', 'silver', 'twinkled', 'falcon', 'snipe', 'killed', 'briefly', 'tiercel', 'tarnished', 'wall', 'east', 'drab', 'filled', 'found', 'river', 'sank', 'motion', 'startled', 'large', 'inland', 'sleekly', 'drifted', 'snow', 'perching', 'gradually', 'yard', 'bulk', 'could', 'part', 'eroded', 'float', 'ploughland', 'yet', 'shore', 'chattered', 'estuary', 'dived', 'became', 'fly', 'gathering', 'upward', 'wood', 'sat', 'simply', 'blur', 'diving', 'though', 'rose', 'fence', 'west', 'resting', 'woodpigeon', 'thin', 'three', 'perch', 'swung', 'day', 'speed', 'tongued', 'curved', 'flash', 'redshank', 'corner', 'frequently', 'bone', 'top', 'diamond', 'changed', 'flooded', 'cloud', 'watching', 'lifted']\n",
      "Maximal independent set length: 149\n"
     ]
    }
   ],
   "source": [
    "checkfile=\"85_apr-3\"\n",
    "_g = graph_dict[\"_\"+checkfile]\n",
    "_gd = graph_data(\"_\"+checkfile+\".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hubs: [(15, 'wood'), (13, 'tree'), (12, 'like')]\n",
      "hubs_deg_sum: 40\n",
      "Loss: -371\n",
      "Diameter: 15\n",
      "Center nodes: ['flew', 'woodpecker', 'wood', 'like', 'drumming', 'song', 'singing', 'bird', 'called', 'go', 'belligerent-looking', 'two', 'a', 'forever', 'leave']\n",
      "Average clustering: 0.01399171959919624\n",
      "Dominating set: {'', 'also', 'cloud', 'bell-like', 'high', 'get', 'looking', 'distance', 'identified', 'tsink', 'noctule', 'clear', 'pinned', 'till', 'sulphur', 'dead', 'quickly', 'sunlight', 'following', 'wide', 'shade', 'coppice', 'insane', 'wait', 'masterful', 'mate', 'marsh', 'occasionally', 'fuzzy', 'frequently', 'arden', 'many', 'note', 'second', 'belligerent-looking', 'tiresome', 'clearly', 'bill', 'seven', 'coast', 'haze', 'pop', 'close', 'watching', 'texture', 'collect', 'glided', 'drowsily', 'huge', 'rested', 'change', 'long', 'shadow', 'hawking', 'bark', 'last', 'sorrow', 'scuttled', 'mechanical', 'woodpecker', 'seem', 'cover', 'follow', 'left', 'answer', 'blow', 'loud', 'eye', 'half', 'hears', 'nest', 'almost', 'wherever', 'coloured', 'lifted', 'early', 'muffled', 'easy', 'october', 'wing', 'combined', 'heavy', 'iris', 'tree', 'broke', 'stiffly', 'east', 'jay', 'forever', 'glorious', 'chittering', 'trill', 'extravagantly', 'travelling', 'chaffinch', 'hollow', 'fall', 'whenever', 'came', 'minute', 'tiercel', 'warily', 'dy', 'back', 'glaze', 'eat', 'vanished', 'bouncing', 'right', 'followed', 'dust-moted', 'bluebell', 'prow', 'thin', 'oclock', 'direction', 'freedom', 'inside', 'eastern', 'unwearying', 'seen', 'soar', 'movement', 'separated', 'flitted', 'speed', 'orchard', 'made', 'even', 'could', 'lean', 'hawk', 'quee', 'go', 'deep', 'far', 'concealed', 'waiting', 'chased', 'south', 'hawfinch', 'merely', 'timid'}\n",
      "Dominating set length: 143\n",
      "Maximal independent set: ['immense', 'bell-like', 'chased', 'till', 'bird', 'moment', 'shade', 'five', 'resting', 'trellis', 'purring', 'speed', 'shone', 'combined', 'identified', 'april', 'rapid', 'hedge', 'timid', 'arden', 'haze', 'first', 'crossing', 'as', 'hollow', 'hawking', 'showed', 'hawk', 'silently', 'bead', 'scent', 'threaded', 'quickly', 'colour', 'dodged', 'seems', 'away', 'vertical', 'twenty', 'wide', 'ball', 'among', 'began', 'many', 'tsink', 'left', 'huge', 'called', 'hard', 'le', 'formed', 'blow', 'across', 'call', 'may', 'feather', 'chittering', 'smell', 'separated', 'surrounding', 'marsh', 'nuthatch', 'high', 'ended', 'glaze', 'cuckoo', 'trill', 'jay', 'close', 'coast', 'bat', 'texture', 'tiresome', 'furry', 'wing', 'sailed', 'drifting', 'chaffinch', 'direction', 'freedom', 'quee', 'hornbeam', 'triangle', 'get', 'half', 'mechanical', 'singing', 'stay', 'movement', 'sings', 'spotted', 'east', 'react', 'golden-coloured', '', 'brook', 'eastern', 'look', 'sunlight', 'last', 'occasionally', 'easy', 'match', 'note', 'month', 'also', 'come', 'saw', 'masterful', 'concealed', 'pop', 'drummed', 'long-tailed', 'dry', 'brown', 'concentration', 'since', 'possibly', 'mate', 'could', 'dispersing', 'clearly', 'thin', 'noisy', 'rebound', 'prow', 'rested', 'rang', 'go', 'robin', 'deep', 'hears', 'watching', 'coppice', 'lifted', 'still', 'softer', 'change', 'green', 'following', 'blue', 'followed', 'even']\n",
      "Maximal independent set length: 143\n"
     ]
    }
   ],
   "source": [
    "g = graph_dict[checkfile]\n",
    "gd = graph_data(checkfile+\".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"750px\"\n",
       "            src=\"graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a2c6bb780>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_graph3(_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"750px\"\n",
       "            src=\"graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a2a527ef0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_graph3(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concordance(text_folder,filename,word,width=100,lines=1000):\n",
    "    # Get the path\n",
    "    text_path = os.path.join(text_folder, filename)\n",
    "    print(text_path)\n",
    "\n",
    "    # Open the file\n",
    "    with open(text_path) as file:\n",
    "        text_txt=file.read()\n",
    "\n",
    "    # make nltk version of the text (useful for concordance)\n",
    "    import nltk\n",
    "    text_words = nltk.word_tokenize(text_txt)\n",
    "    text_nltk = nltk.text.Text(text_words)\n",
    "\n",
    "    # get concordance\n",
    "    text_nltk.concordance(word,width=width,lines=lines)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../corpora/peregrine/_52_jan-9.txt\n",
      "Displaying 1 of 1 matches:\n",
      "hundred woodpigeons clattered up from the mud , like damp squibs . None moved when I walked towards \n",
      "../corpora/peregrine/52_jan-9.txt\n",
      "Displaying 1 of 1 matches:\n",
      "awks . Their eyes see maps of black and white , like a crackle of silent film . The moving black is \n"
     ]
    }
   ],
   "source": [
    "concordance(text_folder,'_'+checkfile+\".txt\",\"like\")\n",
    "concordance(text_folder,checkfile+\".txt\",\"like\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
