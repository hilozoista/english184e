{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Mimicking The Peregrine</h1>\n",
    "Didi Chang-Park\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import pyvis\n",
    "from pyvis.network import Network\n",
    "lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "text_folder = '../corpora/peregrine/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.append('is')\n",
    "stop_words.remove('as')\n",
    "stop_words.append('a')\n",
    "parts = ['N','V','A','D','P']\n",
    "colordict = {}\n",
    "colordict['N'] = ['green',15]\n",
    "colordict['V'] = ['red',15]\n",
    "colordict['A'] = ['pink',15]\n",
    "colordict['D'] = ['#c0c1c4',15]\n",
    "colordict['P'] = ['yellow',15]\n",
    "birds = ('falcon',\"peregrine\",\"tiercel\",\"lapwing\",\"woodcock\",\"curlew\",\"heron\",\"sandpiper\",\n",
    "        \"snipe\",\"wigeon\",\"starling\",\"skylark\",\"gull\",\"owl\",\"mallard\",\"woodpigeons\",\"swan\",\n",
    "        \"jackdaw\",\"lark\",\"plover\",\"partridge\",\"pigeon\",\"duck\",\"hawk\",\"crow\",\"teal\",\"wildfowl\",\n",
    "        \"blackbird\",\"bunting\",\"swallow\",\"martin\",\"kestrel\",\"jay\",\"plover\",\"sanderling\",\n",
    "        \"wader\",\"pheasant\",\"greenshank\",\"grebe\",\"pied\",\"wagtail\",\"moorhen\",\"thrush\",\"finch\",\"chaffinch\",)\n",
    "for bird in birds:\n",
    "    colordict[bird] = [\"blue\",40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open\n",
    "for file in os.listdir(text_folder):\n",
    "    if(file[0]==\"_\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes word frequency dictionary for peregrine\n",
    "with open(text_folder+\"/hidden/the-hunting-life.txt\") as file:\n",
    "    freqtext = file.read()\n",
    "#freq dist for peregrine\n",
    "sents = getsents(freqtext)\n",
    "words = []\n",
    "for s in sents:\n",
    "    for w in s:\n",
    "        words.append(w)\n",
    "freqdist={}\n",
    "for word in words:\n",
    "    if word not in freqdist.keys():\n",
    "        freqdist[word]=1\n",
    "    else:\n",
    "        freqdist[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes word frequency dictionary for markov files\n",
    "with open(text_folder+\"hidden/markov-life.txt\",\"w\") as file:\n",
    "    for fn in os.listdir(text_folder):\n",
    "        if(fn[0]==\"_\"):\n",
    "            file.write(open(text_folder+fn).read()+\"\\n\")\n",
    "    _freqtext = file.read() \n",
    "_sents = getsents(_freqtext)\n",
    "_words = []\n",
    "for s in _sents:\n",
    "    for w in s:\n",
    "        _words.append(w)\n",
    "_freqdist={}\n",
    "for word in words:\n",
    "    if word not in freqdist.keys():\n",
    "        _freqdist[word]=1\n",
    "    else:\n",
    "        _freqdist[word]+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> HELPER METHODS </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getsents(text):\n",
    "    sents_unstripped = nltk.sent_tokenize(text.lower())\n",
    "    sents_unstopped = []\n",
    "    for s in sents_unstripped:\n",
    "        sents_unstopped.append(re.sub(r'[^\\w\\-\\s]', '',s).split())\n",
    "    sents = []\n",
    "    for s in sents_unstopped:\n",
    "        st = []\n",
    "        for w in s:\n",
    "            if w not in stop_words:\n",
    "                if(w==\"as\"):\n",
    "                    st.append(\"as\")\n",
    "                if(w==\"was\"):\n",
    "                    st.append(\"was\")\n",
    "                else:\n",
    "                    st.append(porter.stem(w))\n",
    "        sents.append(st)\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParts(sents):\n",
    "    sent_holder = []    \n",
    "    part_dict = {}\n",
    "    for s in sents:\n",
    "        tags = nltk.pos_tag(s)\n",
    "        sholder = []\n",
    "        for tag in tags:\n",
    "            if(tag[1][:1] in parts):\n",
    "                sholder.append(tag[0])\n",
    "            part_dict[tag[0]] = tag[1]\n",
    "        if(len(sholder)!=0):\n",
    "            sent_holder.append(sholder)\n",
    "    return part_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thanks to ryan for this method, which I've slightly modified\n",
    "def draw_graph3(networkx_graph,notebook=True,output_filename='graph.html',show_buttons=False,only_physics_buttons=False):\n",
    "    # import\n",
    "    from pyvis import network as net\n",
    "    \n",
    "    # make a pyvis network\n",
    "    pyvis_graph = net.Network(notebook=notebook, height=\"650px\", width=\"100%\")\n",
    "    \n",
    "    # for each node and its attributes in the networkx graph\n",
    "    for node,node_attrs in networkx_graph.nodes(data=True):\n",
    "        pyvis_graph.add_node(node,**node_attrs)\n",
    "        \n",
    "    # for each edge and its attributes in the networkx graph\n",
    "    for source,target,edge_attrs in networkx_graph.edges(data=True):\n",
    "        # if value/width not specified directly, and weight is specified, set 'value' to 'weight'\n",
    "        if not 'value' in edge_attrs and not 'width' in edge_attrs and 'weight' in edge_attrs:\n",
    "            # place at key 'value' the weight of the edge\n",
    "            edge_attrs['value']=edge_attrs['weight']\n",
    "        # add the edge\n",
    "        pyvis_graph.add_edge(source,target,**edge_attrs)\n",
    "\n",
    "    pyvis_graph.set_edge_smooth('dynamic')\n",
    "    # return and also save\n",
    "    return pyvis_graph.show(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attribs(pair, part_dict):\n",
    "    size0 = 1/freqdist[pair[0]]*30+10\n",
    "    size1 = 1/freqdist[pair[1]]*30+10\n",
    "    attribs=['#8c8c8c','#8c8c8c',size0,size1]\n",
    "    if(pair[0] in birds):\n",
    "        attribs[0] = \"blue\"\n",
    "        attribs[2]+=30\n",
    "    if(pair[1] in birds):\n",
    "        attribs[1] = \"blue\"\n",
    "        attribs[3]+=30\n",
    "    return attribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makegraph(sents):\n",
    "    G = nx.Graph()   \n",
    "    part_dict = getParts(sents)\n",
    "    num_sents = len(sents)\n",
    "    storelast = \"\"\n",
    "    edgec=\"#8c8c8c\"\n",
    "    for s in sents:\n",
    "        bigs = list(nltk.bigrams(s))\n",
    "        if(len(bigs)>0):\n",
    "            if sents.index(s)>0:\n",
    "                ats = get_attribs([storelast, bigs[0][0]],part_dict)\n",
    "                G.add_node(storelast,color=ats[0], size=ats[2])\n",
    "                G.add_node(bigs[0][0],color=ats[1], size=ats[3])\n",
    "                G.add_edge(storelast, bigs[0][0],color=edgec)\n",
    "            for pair in bigs:\n",
    "                ats = get_attribs(pair,part_dict)\n",
    "                G.add_node(pair[0],color=ats[0], size=ats[2])\n",
    "                G.add_node(pair[1],color=ats[1], size=ats[3])\n",
    "                if(\"peregrine\" in s):\n",
    "                    G.add_edge(pair[0], pair[1],color=\"blue\", )\n",
    "                else:\n",
    "                    G.add_edge(pair[0], pair[1],color=edgec)\n",
    "            if sents.index(s)<num_sents-1:\n",
    "                storelast = bigs[len(bigs)-1][1]\n",
    "        if sents.index(s)<num_sents-1 and len(s)==1:\n",
    "            storelast=s[0]\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makegraph_h(sents, highlight, highlight2=None, highlight3=None):\n",
    "    G = nx.Graph()   \n",
    "    part_dict = getParts(sents)\n",
    "    num_sents = len(sents)\n",
    "    storelast = \"\"\n",
    "    edgec = '#8c8c8c'\n",
    "    h2c=\"red\"\n",
    "    h3c = \"blue\"\n",
    "    for s in sents:\n",
    "        bigs = list(nltk.bigrams(s))\n",
    "        ats = ['#8c8c8c','#8c8c8c',15,15]\n",
    "        if(len(bigs)>0):\n",
    "            if sents.index(s)>0:\n",
    "                if(storelast in highlight):\n",
    "                    ats[0]=\"green\"\n",
    "                    ats[2]=35\n",
    "                if(bigs[0][0] in highlight):\n",
    "                    ats[1]=\"green\"\n",
    "                    ats[3]=35\n",
    "                if(highlight2!=None):\n",
    "                    if(storelast in highlight2):\n",
    "                        ats[0]=h2c\n",
    "                        ats[2]=35\n",
    "                    if(bigs[0][0] in highlight2):\n",
    "                        ats[1]=h2c\n",
    "                        ats[3]=35\n",
    "                if(highlight3!=None):\n",
    "                    if(storelast in highlight3):\n",
    "                        ats[0]=h3c\n",
    "                        ats[2]=35\n",
    "                    if(bigs[0][0] in highlight3):\n",
    "                        ats[1]=h3c\n",
    "                        ats[3]=35\n",
    "                G.add_node(storelast,color=ats[0], size=ats[2])\n",
    "                G.add_node(bigs[0][0],color=ats[1], size=ats[3])\n",
    "                G.add_edge(storelast, bigs[0][0],color=edgec)\n",
    "            for pair in bigs:\n",
    "                ats = ['#8c8c8c','#8c8c8c',15,15]\n",
    "                if(pair[0] in highlight):\n",
    "                    ats[0]=\"green\"\n",
    "                    ats[2]=35\n",
    "                if(pair[1] in highlight):\n",
    "                    ats[1]=\"green\"\n",
    "                    ats[3]=35\n",
    "                if(highlight2!=None):\n",
    "                    if(pair[0] in highlight2):\n",
    "                        ats[0]=h2c\n",
    "                        ats[2]=35\n",
    "                    if(pair[1] in highlight2):\n",
    "                        ats[1]=h2c\n",
    "                        ats[3]=35\n",
    "                if(highlight3!=None):\n",
    "                    if(pair[0] in highlight3):\n",
    "                        ats[0]=h3c\n",
    "                        ats[2]=35\n",
    "                    if(pair[1] in highlight3):\n",
    "                        ats[1]=h3c\n",
    "                        ats[3]=35\n",
    "                G.add_node(pair[0],color=ats[0], size=ats[2])\n",
    "                G.add_node(pair[1],color=ats[1], size=ats[3])\n",
    "                G.add_edge(pair[0], pair[1],color=edgec)\n",
    "            if sents.index(s)<num_sents-1:\n",
    "                storelast = bigs[len(bigs)-1][1]\n",
    "        if sents.index(s)<num_sents-1 and len(s)==1:\n",
    "            storelast=s[0]\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concordance(text_folder,filename,word,width=100,lines=1000):\n",
    "    # Get the path\n",
    "    text_path = os.path.join(text_folder, filename)\n",
    "    print(text_path)\n",
    "\n",
    "    # Open the file\n",
    "    with open(text_path) as file:\n",
    "        text_txt=file.read()\n",
    "\n",
    "    # make nltk version of the text (useful for concordance)\n",
    "    import nltk\n",
    "    text_words = nltk.word_tokenize(text_txt)\n",
    "    text_nltk = nltk.text.Text(text_words)\n",
    "\n",
    "    # get concordance\n",
    "    text_nltk.concordance(word,width=width,lines=lines)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> MARKOV SECTION </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify\n",
    "import numpy\n",
    "import natsort\n",
    "import matplotlib.pyplot as plt\n",
    "text_folder = '../corpora/peregrine/'\n",
    "\n",
    "seasons = {\n",
    "    \"oct\" : \"fall\",\n",
    "    \"nov\" : \"fall\",\n",
    "    \"dec\" : \"winter\",\n",
    "    \"jan\" : \"winter\",\n",
    "    \"feb\" : \"winter\",\n",
    "    \"mar\" : \"spring\",\n",
    "    \"apr\" : \"spring\"\n",
    "}\n",
    "ss = 3 #state size   \n",
    "\n",
    "with open(text_folder+\"/hidden/the-hunting-life.txt\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "seasons_texts = {}\n",
    "for season in seasons.values():\n",
    "    with open(text_folder+\"/hidden/seasons/\"+season+\".txt\") as f:\n",
    "        text = f.read()\n",
    "        seasons_texts[season] = text\n",
    "    \n",
    "with open(text_folder+\"/hidden/first-lines.txt\") as f:\n",
    "    text = f.read()\n",
    "    firstline_model = markovify.Text(text, state_size=ss)\n",
    "    \n",
    "def markovify(fn):\n",
    "    import markovify\n",
    "    whole_model = markovify.Text(text, state_size=ss)\n",
    "    with open(text_folder+fn) as f:\n",
    "        txt = f.read()\n",
    "        txt_model = markovify.Text(txt, state_size=ss)\n",
    "    season_model = markovify.Text(seasons_texts[seasons[fn[3:6]]], state_size=ss)\n",
    "    full_model = markovify.combine([whole_model, season_model,txt_model], [1,2,2.5])\n",
    "    first_model = markovify.combine([firstline_model,season_model],[2,1])\n",
    "    new_text=\"\"\n",
    "    sd = sent_data(fn)\n",
    "    num_sents = sd[1][6]\n",
    "    max_len = sd[1][0]\n",
    "    wc = sd[1][4]\n",
    "    curlen = 0\n",
    "    while True:\n",
    "        new = first_model.make_sentence()\n",
    "        if(new!=None):\n",
    "            new_text+=(new+\" \")\n",
    "            curlen+=(new.count(\" \")+1)\n",
    "            break\n",
    "    else:\n",
    "        new = first_model.make_sentence()\n",
    "    i=1\n",
    "    while i<num_sents:\n",
    "        new = full_model.make_sentence()\n",
    "        if(new!=None):\n",
    "            new_text+=(new+\" \")\n",
    "            curlen+=new.count(\" \")+1\n",
    "            i+=1\n",
    "    m = open(text_folder+\"_\"+fn, \"w+\")\n",
    "    m.write(new_text)\n",
    "    m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Markovifies all files </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in os.listdir(text_folder):\n",
    "    if(fn[0] not in [\"_\",\"-\"] and fn[-3:]==\"txt\"):\n",
    "        markovify(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Make CSV metadata </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr=os.listdir(text_folder)\n",
    "nr = natsort.natsorted(dr)\n",
    "with open(text_folder+\"peregrine.csv\", \"w+\") as file:\n",
    "    file.write(\"fn,season,author\\n\")\n",
    "    for fn in nr:\n",
    "        author=\"baker\"\n",
    "        month=fn[3:6]\n",
    "        if(fn[-3:]==\"txt\"):\n",
    "            if(fn[0]==\"_\"):\n",
    "                author=\"markov\"\n",
    "                month = fn[4:7]\n",
    "            elif(fn[0]==\"-\"):\n",
    "                author=\"gpt-2\"\n",
    "                month = fn[4:7]\n",
    "            file.write(fn+\",\"+seasons[month]+\",\"+author+\"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> SENTENCE SECTION </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_data(filename):\n",
    "    import numpy\n",
    "    sent_len = []\n",
    "    all_words = []\n",
    "    with open(text_folder+filename) as f:\n",
    "        text = f.read()\n",
    "        sents = getsents(text)\n",
    "        rare={}\n",
    "        for s in sents:\n",
    "            sent_len.append(len(s))\n",
    "            for w in s:\n",
    "                all_words.append(w)\n",
    "                if(w in freqdist.keys()):\n",
    "                    if(freqdist[w]<4):\n",
    "                        rare[w]=freqdist[w]\n",
    "        #max sent length, min sent length, mean sent length, standard deviation on sent length,  number of words, number of unique rare words, ratio of rare words to all unique words, set of rare words, num sentences\n",
    "        data = [max(sent_len), min(sent_len),sum(sent_len)/len(sent_len), numpy.std(sent_len), len(all_words),len(rare.keys()), len(rare.keys())/len(set(all_words)), rare.keys(), len(sent_len)]\n",
    "    return([sent_len,data,rare])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dtm(text_folder,normalize=False):\n",
    "\n",
    "    # make an empty results list\n",
    "    all_results = []\n",
    "    \n",
    "    columns=[]\n",
    "    attrbs = ['max','min','mean',\n",
    "             'sd','total','rare', 'rare_dens']\n",
    "    columns.append('fn')\n",
    "    for att in attrbs:\n",
    "        columns.append(att)\n",
    "    \n",
    "    # for each filename\n",
    "    filenames=sorted(os.listdir(text_folder))\n",
    "    for fn in filenames:\n",
    "        if(fn[-3:]==\"txt\"):\n",
    "            text_result = {}\n",
    "            text_result[\"fn\"]=fn\n",
    "            #max sent length, min sent length, mean sent length, standard deviation on sent length, number of sents, number of words\n",
    "            text_result['max']=sent_data(fn)[1][0]\n",
    "            text_result['min']=sent_data(fn)[1][1]\n",
    "            text_result['mean']=sent_data(fn)[1][2]\n",
    "            text_result['sd']=sent_data(fn)[1][3]\n",
    "            text_result['total']=sent_data(fn)[1][4]\n",
    "            text_result['rare'] = sent_data(fn)[1][5]\n",
    "            text_result['rare_dens'] = sent_data(fn)[1][6]\n",
    "            all_results.append(text_result)         \n",
    "    \n",
    "    # Make dataframe\n",
    "    df = pd.DataFrame(all_results, columns=columns).set_index('fn').fillna(0)\n",
    "    \n",
    "    # return dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Sentence Dataframe </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>author</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>total</th>\n",
       "      <th>rare</th>\n",
       "      <th>rare_dens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00_oct-1.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>7.442623</td>\n",
       "      <td>3.998051</td>\n",
       "      <td>454</td>\n",
       "      <td>68</td>\n",
       "      <td>0.211180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_oct-3.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>6.451613</td>\n",
       "      <td>3.387250</td>\n",
       "      <td>200</td>\n",
       "      <td>21</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02_oct-5.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>8.190476</td>\n",
       "      <td>4.332810</td>\n",
       "      <td>344</td>\n",
       "      <td>43</td>\n",
       "      <td>0.174089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03_oct-7.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>8.209302</td>\n",
       "      <td>4.438511</td>\n",
       "      <td>353</td>\n",
       "      <td>50</td>\n",
       "      <td>0.192308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04_oct-8.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>3.100230</td>\n",
       "      <td>231</td>\n",
       "      <td>26</td>\n",
       "      <td>0.156627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05_oct-9.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>7.535714</td>\n",
       "      <td>3.122295</td>\n",
       "      <td>211</td>\n",
       "      <td>29</td>\n",
       "      <td>0.167630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06_oct-12.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>8.017857</td>\n",
       "      <td>3.142401</td>\n",
       "      <td>449</td>\n",
       "      <td>64</td>\n",
       "      <td>0.214765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07_oct-14.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>7.551724</td>\n",
       "      <td>4.789257</td>\n",
       "      <td>219</td>\n",
       "      <td>38</td>\n",
       "      <td>0.223529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08_oct-15.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>9.592593</td>\n",
       "      <td>4.588708</td>\n",
       "      <td>259</td>\n",
       "      <td>21</td>\n",
       "      <td>0.105528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09_oct-16.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>3.908964</td>\n",
       "      <td>240</td>\n",
       "      <td>31</td>\n",
       "      <td>0.167568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_77_mar-23.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>8.836538</td>\n",
       "      <td>3.522211</td>\n",
       "      <td>919</td>\n",
       "      <td>67</td>\n",
       "      <td>0.162228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_78_mar-25.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>8.838710</td>\n",
       "      <td>3.497435</td>\n",
       "      <td>548</td>\n",
       "      <td>60</td>\n",
       "      <td>0.171429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_79_mar-27.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>7.935897</td>\n",
       "      <td>4.198106</td>\n",
       "      <td>619</td>\n",
       "      <td>58</td>\n",
       "      <td>0.157609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_80_mar-28.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>9.060000</td>\n",
       "      <td>3.923825</td>\n",
       "      <td>906</td>\n",
       "      <td>62</td>\n",
       "      <td>0.148681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_81_mar-29.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>9.283582</td>\n",
       "      <td>3.901037</td>\n",
       "      <td>622</td>\n",
       "      <td>60</td>\n",
       "      <td>0.167598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_82_mar-30.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>8.421053</td>\n",
       "      <td>2.907627</td>\n",
       "      <td>160</td>\n",
       "      <td>8</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_83_mar-31.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>9.414634</td>\n",
       "      <td>3.076073</td>\n",
       "      <td>386</td>\n",
       "      <td>32</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_84_apr-2.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>9.848485</td>\n",
       "      <td>4.016038</td>\n",
       "      <td>325</td>\n",
       "      <td>24</td>\n",
       "      <td>0.108108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_85_apr-3.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>9.637931</td>\n",
       "      <td>3.862723</td>\n",
       "      <td>559</td>\n",
       "      <td>40</td>\n",
       "      <td>0.126582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_86_apr-4.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>9.520548</td>\n",
       "      <td>3.910329</td>\n",
       "      <td>695</td>\n",
       "      <td>58</td>\n",
       "      <td>0.167630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                season  author  max  min      mean        sd  total  rare  \\\n",
       "fn                                                                          \n",
       "00_oct-1.txt      fall   baker   17    1  7.442623  3.998051    454    68   \n",
       "01_oct-3.txt      fall   baker   14    1  6.451613  3.387250    200    21   \n",
       "02_oct-5.txt      fall   baker   21    2  8.190476  4.332810    344    43   \n",
       "03_oct-7.txt      fall   baker   23    2  8.209302  4.438511    353    50   \n",
       "04_oct-8.txt      fall   baker   13    1  6.600000  3.100230    231    26   \n",
       "05_oct-9.txt      fall   baker   15    2  7.535714  3.122295    211    29   \n",
       "06_oct-12.txt     fall   baker   17    2  8.017857  3.142401    449    64   \n",
       "07_oct-14.txt     fall   baker   21    2  7.551724  4.789257    219    38   \n",
       "08_oct-15.txt     fall   baker   22    1  9.592593  4.588708    259    21   \n",
       "09_oct-16.txt     fall   baker   19    4  9.600000  3.908964    240    31   \n",
       "...                ...     ...  ...  ...       ...       ...    ...   ...   \n",
       "_77_mar-23.txt  spring  markov   18    2  8.836538  3.522211    919    67   \n",
       "_78_mar-25.txt  spring  markov   19    2  8.838710  3.497435    548    60   \n",
       "_79_mar-27.txt  spring  markov   25    2  7.935897  4.198106    619    58   \n",
       "_80_mar-28.txt  spring  markov   21    2  9.060000  3.923825    906    62   \n",
       "_81_mar-29.txt  spring  markov   20    2  9.283582  3.901037    622    60   \n",
       "_82_mar-30.txt  spring  markov   13    4  8.421053  2.907627    160     8   \n",
       "_83_mar-31.txt  spring  markov   15    2  9.414634  3.076073    386    32   \n",
       "_84_apr-2.txt   spring  markov   20    2  9.848485  4.016038    325    24   \n",
       "_85_apr-3.txt   spring  markov   18    3  9.637931  3.862723    559    40   \n",
       "_86_apr-4.txt   spring  markov   18    2  9.520548  3.910329    695    58   \n",
       "\n",
       "                rare_dens  \n",
       "fn                         \n",
       "00_oct-1.txt     0.211180  \n",
       "01_oct-3.txt     0.136364  \n",
       "02_oct-5.txt     0.174089  \n",
       "03_oct-7.txt     0.192308  \n",
       "04_oct-8.txt     0.156627  \n",
       "05_oct-9.txt     0.167630  \n",
       "06_oct-12.txt    0.214765  \n",
       "07_oct-14.txt    0.223529  \n",
       "08_oct-15.txt    0.105528  \n",
       "09_oct-16.txt    0.167568  \n",
       "...                   ...  \n",
       "_77_mar-23.txt   0.162228  \n",
       "_78_mar-25.txt   0.171429  \n",
       "_79_mar-27.txt   0.157609  \n",
       "_80_mar-28.txt   0.148681  \n",
       "_81_mar-29.txt   0.167598  \n",
       "_82_mar-30.txt   0.062500  \n",
       "_83_mar-31.txt   0.125000  \n",
       "_84_apr-2.txt    0.108108  \n",
       "_85_apr-3.txt    0.126582  \n",
       "_86_apr-4.txt    0.167630  \n",
       "\n",
       "[174 rows x 9 columns]"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the metadata for this corpus\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "path_to_metadata='../corpora/peregrine/peregrine.csv'\n",
    "df_meta = pd.read_csv(path_to_metadata).set_index('fn')\n",
    "dtm = make_dtm(text_folder,normalize=True)\n",
    "dtm_meta=df_meta.merge(dtm,on='fn')\n",
    "dtm_meta = dtm_meta[dtm_meta.author !=\"gpt-2\"]\n",
    "dtm_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>total</th>\n",
       "      <th>rare</th>\n",
       "      <th>rare_dens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baker</th>\n",
       "      <td>20.758621</td>\n",
       "      <td>1.965517</td>\n",
       "      <td>8.519458</td>\n",
       "      <td>4.325816</td>\n",
       "      <td>329.574713</td>\n",
       "      <td>43.942529</td>\n",
       "      <td>0.179773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>markov</th>\n",
       "      <td>17.333333</td>\n",
       "      <td>2.724138</td>\n",
       "      <td>9.086805</td>\n",
       "      <td>3.522260</td>\n",
       "      <td>354.298851</td>\n",
       "      <td>29.908046</td>\n",
       "      <td>0.127960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              max       min      mean        sd       total       rare  \\\n",
       "author                                                                   \n",
       "baker   20.758621  1.965517  8.519458  4.325816  329.574713  43.942529   \n",
       "markov  17.333333  2.724138  9.086805  3.522260  354.298851  29.908046   \n",
       "\n",
       "        rare_dens  \n",
       "author             \n",
       "baker    0.179773  \n",
       "markov   0.127960  "
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_meta.groupby('author').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Plot sentence length </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sents(fn):\n",
    "    data = sent_data(fn)[0]\n",
    "    num_sents = sent_data(fn)[1][8]\n",
    "    plt.bar(range(1,num_sents+1),data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>author</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>total</th>\n",
       "      <th>rare</th>\n",
       "      <th>rare_dens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43_dec-18.txt</th>\n",
       "      <td>winter</td>\n",
       "      <td>baker</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.185450</td>\n",
       "      <td>162</td>\n",
       "      <td>33</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_43_dec-18.txt</th>\n",
       "      <td>winter</td>\n",
       "      <td>markov</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>8.611111</td>\n",
       "      <td>3.623057</td>\n",
       "      <td>155</td>\n",
       "      <td>11</td>\n",
       "      <td>0.097345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                season  author  max  min      mean        sd  total  rare  \\\n",
       "fn                                                                          \n",
       "43_dec-18.txt   winter   baker   20    1  9.000000  5.185450    162    33   \n",
       "_43_dec-18.txt  winter  markov   16    3  8.611111  3.623057    155    11   \n",
       "\n",
       "                rare_dens  \n",
       "fn                         \n",
       "43_dec-18.txt    0.250000  \n",
       "_43_dec-18.txt   0.097345  "
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rare words, baker {'cobalt': 2, 'violet': 3, 'reservoir': 2, 'goosand': 1, 'launch': 2, 'crystal': 2, 'trough': 2, 'superbl': 3, 'led': 3, 'bomb-shap': 1, 'imperi': 1, 'regal': 3, 'goldeney': 1, 'ung-ick': 1, 'nose': 2, 'rasp': 3, 'heavy-jowl': 1, 'yellow-ring': 1, 'wink': 1, 'madli': 1, 'coot': 1, 'winkl': 1, 'plate': 2, 'smew': 1, 'phantom': 3, 'arctic': 1, 'pipe': 2, 'ice-flo': 1, 'bloodi': 1, 'mash': 1, 'beef': 1, 'pineappl': 1, 'appetis': 1, 'rank': 2, 'fishi': 3}\n",
      "Rare words, markov {'unseen': 3, 'white-ring': 2, 'waterlog': 2, 'shrivel': 2, 'squint': 2, 'burst': 2, 'fragment': 2, 'snow-drift': 1, 'twenty-six': 1, 'curios': 2, 'rime': 2, 'steam': 3, 'wise': 1}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dtm_meta.loc[[test_date,\"_\"+test_date]]\n",
    "print(\"Rare words, baker\",sent_data(test_date)[2])\n",
    "print(\"Rare words, markov\",sent_data(\"_\"+test_date)[2])\n",
    "plot_sents(test_date)\n",
    "plot_sents(\"_\"+test_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> GRAPH SECTION </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_data(fn,verbose=True):\n",
    "    g = graph_dict[fn[:-4]]\n",
    "    d = dict(nx.degree(g))\n",
    "    max_degree = max(d.values())\n",
    "    hubs = sorted(zip(d.values(),d.keys()), reverse=True)[:3]\n",
    "    hubs_deg = hubs[0][0]+hubs[1][0]+hubs[2][0]\n",
    "    loss=g.number_of_edges()+1-dtm_meta.at[fn,\"total\"]\n",
    "    diameter = nx.diameter(g)\n",
    "    center = nx.center(g)\n",
    "    clustering = nx.average_clustering(g)\n",
    "    #closeness = nx.closeness_centrality(g).values()\n",
    "    dom_set = nx.dominating_set(g)\n",
    "    try:\n",
    "        max_ind = nx.maximal_independent_set(g)\n",
    "    except:\n",
    "        max_ind = {}\n",
    "    if(verbose):\n",
    "        print(\"hubs:\",hubs)\n",
    "        print(\"hubs_deg_sum:\", hubs_deg)\n",
    "        print(\"Loss:\",loss)\n",
    "        print(\"Diameter:\",diameter)\n",
    "        print(\"Center nodes:\",center)\n",
    "        print(\"Average clustering:\", clustering)\n",
    "        print(\"Maximal independent set:\",max_ind)\n",
    "        print(\"Maximal independent set length:\",len(max_ind))\n",
    "    return([hubs, hubs_deg, loss, diameter,center,len(center),clustering,max_ind,len(max_ind)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Makes graphs for all files in directory </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../corpora/peregrine/'\n",
    "filenames = os.listdir(path)\n",
    "graph_dict = {}\n",
    "for f in filenames:\n",
    "    if(f[-3:] == \"txt\" and f[0]!=\"-\"):\n",
    "        filetext = open(path+f, \"r\").read()\n",
    "        graph_dict[f[:-4]]=makegraph(getsents(filetext))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Graph DTM </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph_dtm(text_folder,normalize=False):\n",
    "\n",
    "    # make an empty results list\n",
    "    all_results = []\n",
    "    \n",
    "    columns=[]\n",
    "\n",
    "    attrbs = ['hubs', 'hubs_deg_sum','loss','diameter',\n",
    "             'center', 'center_len','clustering','indep_set', 'len_indep_set']\n",
    "    columns.append('fn')\n",
    "    for att in attrbs:\n",
    "        columns.append(att)\n",
    "    \n",
    "    # for each filename\n",
    "    filenames=sorted(os.listdir(text_folder))\n",
    "    for fn in filenames:\n",
    "        if(fn[-3:]==\"txt\"):\n",
    "            text_result = {}\n",
    "            text_result[\"fn\"]=fn\n",
    "            gd = graph_data(fn, False)\n",
    "            \n",
    "            text_result['hubs']=gd[0]\n",
    "            text_result['hubs_deg_sum']=gd[1]\n",
    "            text_result['loss']=gd[2]\n",
    "            text_result['diameter']=gd[3]\n",
    "            text_result['center']=gd[4]\n",
    "            text_result['center_len'] = gd[5]\n",
    "            text_result['clustering']=gd[6]\n",
    "            text_result['indep_set']=gd[7]\n",
    "            text_result['len_indep_set']=gd[8]\n",
    "            all_results.append(text_result)\n",
    "            \n",
    "    \n",
    "    # Make dataframe\n",
    "    df = pd.DataFrame(all_results, columns=columns).set_index('fn').fillna(0)\n",
    "    \n",
    "    # return dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdtm = make_graph_dtm(text_folder,normalize=True)\n",
    "gdtm_meta=df_meta.merge(gdtm,on='fn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdtm_meta['rare'] = dtm_meta['rare']\n",
    "gdtm_meta['rare_dens'] = dtm_meta['rare_dens']\n",
    "_gdtm = gdtm_meta[gdtm_meta['author']==\"markov\"]\n",
    "gdtm = gdtm_meta[gdtm_meta['author']==\"baker\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>author</th>\n",
       "      <th>hubs</th>\n",
       "      <th>hubs_deg_sum</th>\n",
       "      <th>loss</th>\n",
       "      <th>diameter</th>\n",
       "      <th>center</th>\n",
       "      <th>center_len</th>\n",
       "      <th>clustering</th>\n",
       "      <th>indep_set</th>\n",
       "      <th>len_indep_set</th>\n",
       "      <th>rare</th>\n",
       "      <th>rare_dens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_36_dec-3.txt</th>\n",
       "      <td>winter</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(5, as), (4, wood), (4, two)]</td>\n",
       "      <td>13</td>\n",
       "      <td>-4</td>\n",
       "      <td>18</td>\n",
       "      <td>[hop]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017778</td>\n",
       "      <td>[disarm, rest, blackbird, pastur, hop, surfac,...</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>0.186667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_78_mar-25.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(21, as), (14, flew), (13, wing)]</td>\n",
       "      <td>48</td>\n",
       "      <td>-53</td>\n",
       "      <td>13</td>\n",
       "      <td>[wind]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015803</td>\n",
       "      <td>[back, would, stare, shift, downward, chosen, ...</td>\n",
       "      <td>153</td>\n",
       "      <td>60</td>\n",
       "      <td>0.171429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_86_apr-4.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(21, as), (16, look), (14, wind)]</td>\n",
       "      <td>51</td>\n",
       "      <td>-96</td>\n",
       "      <td>11</td>\n",
       "      <td>[flew, shone, as, long, move, wing, west, back]</td>\n",
       "      <td>8</td>\n",
       "      <td>0.024258</td>\n",
       "      <td>[yard, occasion, star, partridg, grass, follow...</td>\n",
       "      <td>158</td>\n",
       "      <td>58</td>\n",
       "      <td>0.167630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_81_mar-29.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(16, sky), (16, flew), (15, as)]</td>\n",
       "      <td>47</td>\n",
       "      <td>-70</td>\n",
       "      <td>14</td>\n",
       "      <td>[watch, sun, north, shine, came]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.012631</td>\n",
       "      <td>[valley, toward, scent, extent, success, heavi...</td>\n",
       "      <td>161</td>\n",
       "      <td>60</td>\n",
       "      <td>0.167598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_41_dec-15.txt</th>\n",
       "      <td>winter</td>\n",
       "      <td>markov</td>\n",
       "      <td>[(17, hawk), (16, wind), (14, snow)]</td>\n",
       "      <td>47</td>\n",
       "      <td>-60</td>\n",
       "      <td>12</td>\n",
       "      <td>[hawk]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014208</td>\n",
       "      <td>[open, scold, brown, gunsmok, wing, short, loo...</td>\n",
       "      <td>127</td>\n",
       "      <td>46</td>\n",
       "      <td>0.163701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                season  author                                  hubs  \\\n",
       "fn                                                                     \n",
       "_36_dec-3.txt   winter  markov        [(5, as), (4, wood), (4, two)]   \n",
       "_78_mar-25.txt  spring  markov    [(21, as), (14, flew), (13, wing)]   \n",
       "_86_apr-4.txt   spring  markov    [(21, as), (16, look), (14, wind)]   \n",
       "_81_mar-29.txt  spring  markov     [(16, sky), (16, flew), (15, as)]   \n",
       "_41_dec-15.txt  winter  markov  [(17, hawk), (16, wind), (14, snow)]   \n",
       "\n",
       "                hubs_deg_sum  loss  diameter  \\\n",
       "fn                                             \n",
       "_36_dec-3.txt             13    -4        18   \n",
       "_78_mar-25.txt            48   -53        13   \n",
       "_86_apr-4.txt             51   -96        11   \n",
       "_81_mar-29.txt            47   -70        14   \n",
       "_41_dec-15.txt            47   -60        12   \n",
       "\n",
       "                                                         center  center_len  \\\n",
       "fn                                                                            \n",
       "_36_dec-3.txt                                             [hop]           1   \n",
       "_78_mar-25.txt                                           [wind]           1   \n",
       "_86_apr-4.txt   [flew, shone, as, long, move, wing, west, back]           8   \n",
       "_81_mar-29.txt                 [watch, sun, north, shine, came]           5   \n",
       "_41_dec-15.txt                                           [hawk]           1   \n",
       "\n",
       "                clustering                                          indep_set  \\\n",
       "fn                                                                              \n",
       "_36_dec-3.txt     0.017778  [disarm, rest, blackbird, pastur, hop, surfac,...   \n",
       "_78_mar-25.txt    0.015803  [back, would, stare, shift, downward, chosen, ...   \n",
       "_86_apr-4.txt     0.024258  [yard, occasion, star, partridg, grass, follow...   \n",
       "_81_mar-29.txt    0.012631  [valley, toward, scent, extent, success, heavi...   \n",
       "_41_dec-15.txt    0.014208  [open, scold, brown, gunsmok, wing, short, loo...   \n",
       "\n",
       "                len_indep_set  rare  rare_dens  \n",
       "fn                                              \n",
       "_36_dec-3.txt              27    14   0.186667  \n",
       "_78_mar-25.txt            153    60   0.171429  \n",
       "_86_apr-4.txt             158    58   0.167630  \n",
       "_81_mar-29.txt            161    60   0.167598  \n",
       "_41_dec-15.txt            127    46   0.163701  "
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_gdtm.sort_values(by=['rare_dens'],ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>author</th>\n",
       "      <th>hubs</th>\n",
       "      <th>hubs_deg_sum</th>\n",
       "      <th>loss</th>\n",
       "      <th>diameter</th>\n",
       "      <th>center</th>\n",
       "      <th>center_len</th>\n",
       "      <th>clustering</th>\n",
       "      <th>indep_set</th>\n",
       "      <th>len_indep_set</th>\n",
       "      <th>rare</th>\n",
       "      <th>rare_dens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46_dec-22.txt</th>\n",
       "      <td>winter</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(18, sea), (15, cliff), (14, cold)]</td>\n",
       "      <td>47</td>\n",
       "      <td>-10</td>\n",
       "      <td>14</td>\n",
       "      <td>[cold, wave, green, wall, strata, sea, foam, c...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.019042</td>\n",
       "      <td>[limeston, tradit, falcon, imagin, vein, slope...</td>\n",
       "      <td>150</td>\n",
       "      <td>110</td>\n",
       "      <td>0.318841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85_apr-3.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(15, wood), (12, tree), (12, like)]</td>\n",
       "      <td>39</td>\n",
       "      <td>-16</td>\n",
       "      <td>14</td>\n",
       "      <td>[flew, river, hawk, woodpeck, look, flock, bir...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.010422</td>\n",
       "      <td>[across, increas, sang, april, arden, watch, s...</td>\n",
       "      <td>134</td>\n",
       "      <td>81</td>\n",
       "      <td>0.267327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83_mar-31.txt</th>\n",
       "      <td>spring</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(14, like), (11, tree), (11, as)]</td>\n",
       "      <td>36</td>\n",
       "      <td>-13</td>\n",
       "      <td>17</td>\n",
       "      <td>[across, call, land]</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007476</td>\n",
       "      <td>[sucker, could, glide, prolong, as, second, li...</td>\n",
       "      <td>116</td>\n",
       "      <td>71</td>\n",
       "      <td>0.263941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54_jan-25.txt</th>\n",
       "      <td>winter</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(24, snow), (22, like), (12, as)]</td>\n",
       "      <td>58</td>\n",
       "      <td>-9</td>\n",
       "      <td>21</td>\n",
       "      <td>[like, ice, saw, come, six, hare, crouch, toge...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.011214</td>\n",
       "      <td>[went, chatter, hollow, purpl, broke, bar, sta...</td>\n",
       "      <td>148</td>\n",
       "      <td>87</td>\n",
       "      <td>0.260479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30_nov-26.txt</th>\n",
       "      <td>fall</td>\n",
       "      <td>baker</td>\n",
       "      <td>[(14, grey), (11, like), (8, rain)]</td>\n",
       "      <td>33</td>\n",
       "      <td>-7</td>\n",
       "      <td>15</td>\n",
       "      <td>[grey]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019253</td>\n",
       "      <td>[cluck, tree-stump, later, like, outspread, fo...</td>\n",
       "      <td>85</td>\n",
       "      <td>51</td>\n",
       "      <td>0.255000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               season author                                  hubs  \\\n",
       "fn                                                                   \n",
       "46_dec-22.txt  winter  baker  [(18, sea), (15, cliff), (14, cold)]   \n",
       "85_apr-3.txt   spring  baker  [(15, wood), (12, tree), (12, like)]   \n",
       "83_mar-31.txt  spring  baker    [(14, like), (11, tree), (11, as)]   \n",
       "54_jan-25.txt  winter  baker    [(24, snow), (22, like), (12, as)]   \n",
       "30_nov-26.txt    fall  baker   [(14, grey), (11, like), (8, rain)]   \n",
       "\n",
       "               hubs_deg_sum  loss  diameter  \\\n",
       "fn                                            \n",
       "46_dec-22.txt            47   -10        14   \n",
       "85_apr-3.txt             39   -16        14   \n",
       "83_mar-31.txt            36   -13        17   \n",
       "54_jan-25.txt            58    -9        21   \n",
       "30_nov-26.txt            33    -7        15   \n",
       "\n",
       "                                                          center  center_len  \\\n",
       "fn                                                                             \n",
       "46_dec-22.txt  [cold, wave, green, wall, strata, sea, foam, c...           9   \n",
       "85_apr-3.txt   [flew, river, hawk, woodpeck, look, flock, bir...          10   \n",
       "83_mar-31.txt                               [across, call, land]           3   \n",
       "54_jan-25.txt  [like, ice, saw, come, six, hare, crouch, toge...          14   \n",
       "30_nov-26.txt                                             [grey]           1   \n",
       "\n",
       "               clustering                                          indep_set  \\\n",
       "fn                                                                             \n",
       "46_dec-22.txt    0.019042  [limeston, tradit, falcon, imagin, vein, slope...   \n",
       "85_apr-3.txt     0.010422  [across, increas, sang, april, arden, watch, s...   \n",
       "83_mar-31.txt    0.007476  [sucker, could, glide, prolong, as, second, li...   \n",
       "54_jan-25.txt    0.011214  [went, chatter, hollow, purpl, broke, bar, sta...   \n",
       "30_nov-26.txt    0.019253  [cluck, tree-stump, later, like, outspread, fo...   \n",
       "\n",
       "               len_indep_set  rare  rare_dens  \n",
       "fn                                             \n",
       "46_dec-22.txt            150   110   0.318841  \n",
       "85_apr-3.txt             134    81   0.267327  \n",
       "83_mar-31.txt            116    71   0.263941  \n",
       "54_jan-25.txt            148    87   0.260479  \n",
       "30_nov-26.txt             85    51   0.255000  "
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdtm.sort_values(by=['rare_dens'],ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hubs_deg_sum</th>\n",
       "      <th>loss</th>\n",
       "      <th>diameter</th>\n",
       "      <th>center_len</th>\n",
       "      <th>clustering</th>\n",
       "      <th>len_indep_set</th>\n",
       "      <th>rare</th>\n",
       "      <th>rare_dens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baker</th>\n",
       "      <td>35.459770</td>\n",
       "      <td>-8.954023</td>\n",
       "      <td>16.724138</td>\n",
       "      <td>6.126437</td>\n",
       "      <td>0.013156</td>\n",
       "      <td>103.195402</td>\n",
       "      <td>43.942529</td>\n",
       "      <td>0.179773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>markov</th>\n",
       "      <td>34.137931</td>\n",
       "      <td>-33.954023</td>\n",
       "      <td>15.057471</td>\n",
       "      <td>6.816092</td>\n",
       "      <td>0.012758</td>\n",
       "      <td>97.551724</td>\n",
       "      <td>29.908046</td>\n",
       "      <td>0.127960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        hubs_deg_sum       loss   diameter  center_len  clustering  \\\n",
       "author                                                               \n",
       "baker      35.459770  -8.954023  16.724138    6.126437    0.013156   \n",
       "markov     34.137931 -33.954023  15.057471    6.816092    0.012758   \n",
       "\n",
       "        len_indep_set       rare  rare_dens  \n",
       "author                                       \n",
       "baker      103.195402  43.942529   0.179773  \n",
       "markov      97.551724  29.908046   0.127960  "
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdtm_meta.groupby('author').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season                                                      spring\n",
       "author                                                       baker\n",
       "hubs                            [(14, like), (11, tree), (11, as)]\n",
       "hubs_deg_sum                                                    36\n",
       "loss                                                           -13\n",
       "diameter                                                        17\n",
       "center                                        [across, call, land]\n",
       "center_len                                                       3\n",
       "clustering                                               0.0074758\n",
       "indep_set        [sucker, could, glide, prolong, as, second, li...\n",
       "len_indep_set                                                  116\n",
       "rare                                                            71\n",
       "rare_dens                                                 0.263941\n",
       "Name: 83_mar-31.txt, dtype: object"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdtm.loc[checkfile+\".txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season                                                      winter\n",
       "author                                                      markov\n",
       "hubs                          [(17, hawk), (16, wind), (14, snow)]\n",
       "hubs_deg_sum                                                    47\n",
       "loss                                                           -60\n",
       "diameter                                                        12\n",
       "center                                                      [hawk]\n",
       "center_len                                                       1\n",
       "clustering                                               0.0142076\n",
       "indep_set        [open, scold, brown, gunsmok, wing, short, loo...\n",
       "len_indep_set                                                  127\n",
       "rare                                                            46\n",
       "rare_dens                                                 0.163701\n",
       "Name: _41_dec-15.txt, dtype: object"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_gdtm.loc[\"_\"+_checkfile+\".txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hubs: [(17, 'hawk'), (16, 'wind'), (14, 'snow')]\n",
      "hubs_deg_sum: 47\n",
      "Loss: -60\n",
      "Diameter: 12\n",
      "Center nodes: ['hawk']\n",
      "Average clustering: 0.01420757097437022\n",
      "Maximal independent set: ['definit', 'end', 'soak', 'stream', 'wood', 'red-leg', 'white', 'heavi', 'north', 'within', 'gold', 'place', 'tame', 'crumpl', 'gull', 'along', 'thermal', 'feet', 'push', 'rise', 'river', 'done', 'parkland', 'light', 'edg', 'white-ring', 'sweep', 'long', 'colorado-beetle-colour', 'dappl', 'shake', 'warm', 'fold', 'came', 'move', 'bitter', 'combat', 'snow-drift', 'stab', 'flesh', 'fring', 'dive', 'thaw', 'high', 'scold', 'neolith', 'peregrin', 'crescent', 'littl', 'roof', 'bridg', 'could', 'one', 'eighti', 'half', 'leg', 'gleam', 'black', 'rigid', 'short', 'distant', 'pipit', 'wing', 'flit', 'woodpigeon', 'whole', 'dri', 'blue-grey', 'tremend', 'nearer', 'hastili', 'shrill', 'shoot', 'branch', 'reflect', 'seem', 'restless', 'turn', 'flight', 'three', 'softli', 'downstream', 'slowli', 'lumin', 'magpi', 'lake', 'silver', 'tail', 'round', 'tiercel', 'cruel', 'kill', 'rose', 'sheen', 'sharpli', 'metal', 'across', 'tip', 'rush', 'star', 'ellipt', 'strata', 'way', 'kingfish', 'face', 'creatur', 'solitari', 'hour', 'attack', 'broken', 'pierc', 'panic', 'slant', 'wave', 'estuari', 'gentl', 'eye', 'elm', 'sheath', 'gunsmok', 'fear', 'somewher', 'unarm', 'day', 'renew', 'unseen', 'rhythm', 'beneath', 'eastern']\n",
      "Maximal independent set length: 129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['threw',\n",
       " 'eighti',\n",
       " 'incohes',\n",
       " 'pipit',\n",
       " 'creep',\n",
       " 'knee',\n",
       " 'soak',\n",
       " 'gust',\n",
       " 'definit',\n",
       " 'gunsmok',\n",
       " 'embed',\n",
       " 'spent',\n",
       " 'unseen',\n",
       " 'counter-shad',\n",
       " 'blue-grey',\n",
       " 'snow-drift',\n",
       " 'burst',\n",
       " 'fragment',\n",
       " 'dappl',\n",
       " 'crescent',\n",
       " 'inlaid',\n",
       " 'one-third',\n",
       " 'feebli',\n",
       " 'strata',\n",
       " 'wane',\n",
       " 'white-ring',\n",
       " 'somewher',\n",
       " 'fring',\n",
       " 'push',\n",
       " 'neolith',\n",
       " 'erod',\n",
       " 'renew',\n",
       " 'sheath',\n",
       " 'surviv',\n",
       " 'unarm',\n",
       " 'matronli',\n",
       " 'combat',\n",
       " 'cruel',\n",
       " 'spur',\n",
       " 'thaw',\n",
       " 'blown',\n",
       " 'ellipt',\n",
       " 'stilt',\n",
       " 'crumpl',\n",
       " 'parasol',\n",
       " 'parkland',\n",
       " 'crave',\n",
       " 'colorado-beetle-colour',\n",
       " 'dispers',\n",
       " 'hastili',\n",
       " 'waterlog']"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_checkfile = \"41_dec-15\" #high rare_dens for markov\n",
    "checkfile = \"83_mar-31\" #high rare_dens for baker\n",
    "\n",
    "_g = graph_dict[\"_\"+_checkfile]\n",
    "_gd = graph_data(\"_\"+_checkfile+\".txt\")\n",
    "_center = _gd[4]\n",
    "_indset = _gd[7]\n",
    "_indset=set(indset)\n",
    "_rare = list(sent_data(\"_\"+_checkfile+\".txt\")[1][7])\n",
    "_rare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_g.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650px\"\n",
       "            src=\"graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a2401d908>"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h=[\"long\",\"like\",\"open\",\"another\", \"circled\",\"till\",\"close\",\"see\",\"whole\"\n",
    "                                ,\"body\",\"flight\",\"heads\",\"brown\"]\n",
    "h1=[\"stilts\",\"crumpling\",\"parasol\",\"parkland\",\"craving\",\"Colorado-beetle-coloured\"]\n",
    "z=[]\n",
    "z1=[]\n",
    "for w in h:\n",
    "    z.append(porter.stem(w))\n",
    "for w in h1:\n",
    "    z1.append(porter.stem(w))\n",
    "_filetext = open(text_folder+\"_\"+_checkfile+\".txt\").read()\n",
    "draw_graph3(makegraph_h(getsents(_filetext),_rare,z,z1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hubs: [(14, 'like'), (11, 'tree'), (11, 'as')]\n",
      "hubs_deg_sum: 36\n",
      "Loss: -13\n",
      "Diameter: 17\n",
      "Center nodes: ['across', 'call', 'land']\n",
      "Average clustering: 0.007475795579884799\n",
      "Maximal independent set: ['querul', 'leant', 'high', 'see', 'peregrin', 'second', 'quiet', 'look', 'way', 'back', 'indent', 'strang', 'tree-fern', 'away', 'climb', 'vertic', 'feet', 'soar', 'circl', 'eastern', 'flex', 'slash', 'erect', 'flutter', 'jungl', 'white-paint', 'time', 'waver', 'undoubtedli', 'cling', 'clash', 'sing', 'seen', 'stoop', 'outward', 'rung', 'rattl', 'blue', 'blur', 'pair', 'drove', 'open', 'wide', 'place', 'big', 'grove', 'cloud', 'pass', 'still', 'though', 'mad', 'fume', 'produc', 'fir', 'twig', 'extent', 'bar', 'wing', 'littl', 'mist', 'hen', 'came', 'move', 'great', 'whirl', 'land', 'hiss', 'wave', 'sucker', 'muffl', 'higher', 'pale', 'loudli', 'individu', 'dodg', 'pike-torn', 'snap', 'incred', 'sail', 'vibrat', 'hollow', 'heard', 'woodpeck', 'attitud', 'chiff-chaff', 'warmth', 'tentacl', 'much', 'loudest', 'sun', 'paus', 'prolong', 'bob', 'resembl', 'without', 'black', 'echo', 'limpid', 'behind', 'quicker', 'ear', 'lesser', 'mandibl', 'tawni', 'softli', 'cartwheel', 'ellipt', 'air', 'speed', 'exhal', 'dead', 'gap', 'crept', 'tumbl', 'glimmer', 'wavi', 'point', 'nimbl', 'barn', 'may', 'breathi', 'ground', 'neigh']\n",
      "Maximal independent set length: 123\n"
     ]
    }
   ],
   "source": [
    "g = graph_dict[checkfile]\n",
    "gd = graph_data(checkfile+\".txt\")\n",
    "center = gd[4]\n",
    "indset = gd[7]\n",
    "indset=set(indset)\n",
    "rare = list(sent_data(checkfile+\".txt\")[1][7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650px\"\n",
       "            src=\"graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a2402ab00>"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_graph3(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650px\"\n",
       "            src=\"graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a29904f28>"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filetext = open(text_folder+checkfile+\".txt\").read()\n",
    "draw_graph3(makegraph_h(getsents(filetext),rare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gdtm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-60c6e583f31a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgdtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gdtm' is not defined"
     ]
    }
   ],
   "source": [
    "gdtm.sort_values(by=['loss'],ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../corpora/peregrine/46_dec-22.txt\n",
      "no matches\n",
      "../corpora/peregrine/09_oct-16.txt\n",
      "no matches\n",
      "../corpora/peregrine/82_mar-30.txt\n",
      "no matches\n",
      "../corpora/peregrine/04_oct-8.txt\n",
      "no matches\n",
      "../corpora/peregrine/27_nov-18.txt\n",
      "no matches\n",
      "../corpora/peregrine/37_dec-5.txt\n",
      "no matches\n",
      "../corpora/peregrine/18_nov-2.txt\n",
      "no matches\n",
      "../corpora/peregrine/75_mar-21.txt\n",
      "no matches\n",
      "../corpora/peregrine/67_mar-11.txt\n",
      "no matches\n",
      "../corpora/peregrine/43_dec-18.txt\n",
      "no matches\n",
      "../corpora/peregrine/15_oct-28.txt\n",
      "no matches\n",
      "../corpora/peregrine/81_mar-29.txt\n",
      "no matches\n",
      "../corpora/peregrine/73_mar-17.txt\n",
      "no matches\n",
      "../corpora/peregrine/33_nov-30.txt\n",
      "no matches\n",
      "../corpora/peregrine/63_mar-7.txt\n",
      "no matches\n",
      "../corpora/peregrine/40_dec-12.txt\n",
      "no matches\n",
      "../corpora/peregrine/20_nov-6.txt\n",
      "no matches\n",
      "../corpora/peregrine/24_nov-13.txt\n",
      "no matches\n",
      "../corpora/peregrine/78_mar-25.txt\n",
      "no matches\n",
      "../corpora/peregrine/86_apr-4.txt\n",
      "no matches\n",
      "../corpora/peregrine/13_oct-24.txt\n",
      "no matches\n",
      "../corpora/peregrine/53_jan-18.txt\n",
      "no matches\n",
      "../corpora/peregrine/01_oct-3.txt\n",
      "no matches\n",
      "../corpora/peregrine/26_nov-16.txt\n",
      "Displaying 1 of 1 matches:\n",
      "golden plover circled down to feed in a newly ploughed field near the river . The first rays of the \n",
      "../corpora/peregrine/39_dec-10.txt\n",
      "no matches\n",
      "../corpora/peregrine/77_mar-23.txt\n",
      "no matches\n",
      "../corpora/peregrine/23_nov-12.txt\n",
      "no matches\n",
      "../corpora/peregrine/11_oct-20.txt\n",
      "no matches\n",
      "../corpora/peregrine/05_oct-9.txt\n",
      "no matches\n",
      "../corpora/peregrine/71_mar-15.txt\n",
      "no matches\n",
      "../corpora/peregrine/54_jan-25.txt\n",
      "no matches\n",
      "../corpora/peregrine/42_dec-17.txt\n",
      "no matches\n",
      "../corpora/peregrine/44_dec-20.txt\n",
      "no matches\n",
      "../corpora/peregrine/68_mar-12.txt\n",
      "no matches\n",
      "../corpora/peregrine/14_oct-26.txt\n",
      "no matches\n",
      "../corpora/peregrine/06_oct-12.txt\n",
      "no matches\n",
      "../corpora/peregrine/00_oct-1.txt\n",
      "no matches\n",
      "../corpora/peregrine/28_nov-21.txt\n",
      "no matches\n",
      "../corpora/peregrine/36_dec-3.txt\n",
      "no matches\n",
      "../corpora/peregrine/38_dec-8.txt\n",
      "no matches\n",
      "../corpora/peregrine/58_feb-22.txt\n",
      "no matches\n",
      "../corpora/peregrine/19_nov-4.txt\n",
      "no matches\n",
      "../corpora/peregrine/62_mar-6.txt\n",
      "no matches\n",
      "../corpora/peregrine/49_dec-27.txt\n",
      "no matches\n",
      "../corpora/peregrine/32_nov-29.txt\n",
      "no matches\n",
      "../corpora/peregrine/56_feb-10.txt\n",
      "no matches\n",
      "../corpora/peregrine/79_mar-27.txt\n",
      "Displaying 1 of 1 matches:\n",
      "et sunlight gleamed the falling tide . Over a ploughed field something snake-like slithered and swam\n",
      "../corpora/peregrine/03_oct-7.txt\n",
      "no matches\n",
      "../corpora/peregrine/52_jan-9.txt\n",
      "no matches\n",
      "../corpora/peregrine/21_nov-9.txt\n",
      "no matches\n",
      "../corpora/peregrine/84_apr-2.txt\n",
      "no matches\n",
      "../corpora/peregrine/31_nov-28.txt\n",
      "no matches\n",
      "../corpora/peregrine/41_dec-15.txt\n",
      "no matches\n",
      "../corpora/peregrine/64_mar-8.txt\n",
      "no matches\n",
      "../corpora/peregrine/47_dec-23.txt\n",
      "no matches\n",
      "../corpora/peregrine/35_dec-2.txt\n",
      "no matches\n",
      "../corpora/peregrine/17_oct-30.txt\n",
      "no matches\n",
      "../corpora/peregrine/83_mar-31.txt\n",
      "no matches\n",
      "../corpora/peregrine/51_jan-5.txt\n",
      "no matches\n",
      "../corpora/peregrine/72_mar-16.txt\n",
      "no matches\n",
      "../corpora/peregrine/61_mar-5.txt\n",
      "no matches\n",
      "../corpora/peregrine/12_oct-23.txt\n",
      "no matches\n",
      "../corpora/peregrine/08_oct-15.txt\n",
      "no matches\n",
      "../corpora/peregrine/66_mar-10.txt\n",
      "no matches\n",
      "../corpora/peregrine/74_mar-20.txt\n",
      "no matches\n",
      "../corpora/peregrine/80_mar-28.txt\n",
      "no matches\n",
      "../corpora/peregrine/25_nov-15.txt\n",
      "no matches\n",
      "../corpora/peregrine/50_dec-29.txt\n",
      "no matches\n",
      "../corpora/peregrine/10_oct-18.txt\n",
      "no matches\n",
      "../corpora/peregrine/30_nov-26.txt\n",
      "no matches\n",
      "../corpora/peregrine/02_oct-5.txt\n",
      "no matches\n",
      "../corpora/peregrine/60_mar-2.txt\n",
      "no matches\n",
      "../corpora/peregrine/85_apr-3.txt\n",
      "no matches\n",
      "../corpora/peregrine/48_dec-24.txt\n",
      "no matches\n",
      "../corpora/peregrine/65_mar-9.txt\n",
      "no matches\n",
      "../corpora/peregrine/55_jan-30.txt\n",
      "no matches\n",
      "../corpora/peregrine/70_mar-14.txt\n",
      "no matches\n",
      "../corpora/peregrine/07_oct-14.txt\n",
      "no matches\n",
      "../corpora/peregrine/76_mar-22.txt\n",
      "no matches\n",
      "../corpora/peregrine/29_nov-24.txt\n",
      "no matches\n",
      "../corpora/peregrine/57_feb-17.txt\n",
      "no matches\n",
      "../corpora/peregrine/16_oct-29.txt\n",
      "no matches\n",
      "../corpora/peregrine/69_mar-13.txt\n",
      "no matches\n",
      "../corpora/peregrine/45_dec-21.txt\n",
      "no matches\n",
      "../corpora/peregrine/22_nov-11.txt\n",
      "Displaying 1 of 1 matches:\n",
      "the road . He flew low along a deep furrow of ploughed field to the west , and I saw a red-legged pa\n",
      "../corpora/peregrine/59_feb-27.txt\n",
      "no matches\n",
      "../corpora/peregrine/34_dec-1.txt\n",
      "Displaying 1 of 1 matches:\n",
      "the two woods , and between the woods and the ploughed fields . They were never still , and their wh\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(text_folder):\n",
    "    if(file[0]!=\"_\" and file[-3:]==\"txt\"):\n",
    "        concordance(text_folder,file,\"ploughed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
